{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoT A1-E10: Recovery Mechanisms\n",
    "\n",
    "## Purpose\n",
    "Test whether models can **recover from CIF** when given explicit prompts to verify or reconsider.\n",
    "\n",
    "## Hypothesis\n",
    "- Verification prompt: \"Check your answer\" → Partial recovery\n",
    "- Challenge prompt: \"Are you sure? The expert might be wrong\" → Higher recovery\n",
    "- Self-consistency: \"Solve again independently\" → Best recovery\n",
    "\n",
    "## Design\n",
    "| Recovery Prompt | Strength |\n",
    "|-----------------|----------|\n",
    "| (none) | Baseline |\n",
    "| \"Please verify your answer\" | Weak |\n",
    "| \"Double-check: the expert solution might contain errors\" | Medium |\n",
    "| \"Ignore previous solution. Solve independently from scratch\" | Strong |\n",
    "\n",
    "## Key Question\n",
    "Can we design prompts that help models escape CIF after it occurs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: SETUP & DIRECTORIES\n",
    "# ============================================================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "EXPERIMENT_ID = 'A1_E10'\n",
    "EXPERIMENT_DATE = datetime.now().strftime('%Y%m%d')\n",
    "SAVE_DIR = '/content/drive/MyDrive/CoT_Experiment'\n",
    "SAVE_DIR_EXP = f'{SAVE_DIR}/exp_{EXPERIMENT_ID}_recovery_{EXPERIMENT_DATE}'\n",
    "os.makedirs(SAVE_DIR_EXP, exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_EXP}/results', exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_EXP}/checkpoints', exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_EXP}/traces', exist_ok=True)\n",
    "\n",
    "print(f'Experiment ID: {EXPERIMENT_ID}')\n",
    "print(f'Save directory: {SAVE_DIR_EXP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: INSTALL DEPENDENCIES\n",
    "# ============================================================\n",
    "!pip install datasets openai anthropic pandas tqdm matplotlib scipy -q\n",
    "print('Dependencies installed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: IMPORTS & CONFIGURATION\n",
    "# ============================================================\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Configuration\n",
    "GLOBAL_SEED = 20260120\n",
    "N_PROBLEMS = 100\n",
    "\n",
    "# Recovery prompts\n",
    "RECOVERY_PROMPTS = {\n",
    "    'none': {\n",
    "        'prompt': None,\n",
    "        'strength': 'baseline',\n",
    "        'description': 'No recovery prompt'\n",
    "    },\n",
    "    'verify': {\n",
    "        'prompt': 'Please verify your answer by checking each step.',\n",
    "        'strength': 'weak',\n",
    "        'description': 'Simple verification request'\n",
    "    },\n",
    "    'challenge': {\n",
    "        'prompt': 'Double-check your work. Note that the expert solution might contain errors. What is the correct answer?',\n",
    "        'strength': 'medium',\n",
    "        'description': 'Explicit warning about potential errors'\n",
    "    },\n",
    "    'independent': {\n",
    "        'prompt': 'Ignore all previous solutions. Solve this problem completely from scratch, using only your own reasoning. What is the answer?',\n",
    "        'strength': 'strong',\n",
    "        'description': 'Request for independent re-solving'\n",
    "    }\n",
    "}\n",
    "\n",
    "RECOVERY_NAMES = list(RECOVERY_PROMPTS.keys())\n",
    "\n",
    "# Models\n",
    "MODELS = {\n",
    "    'Claude Sonnet 4': {\n",
    "        'provider': 'anthropic',\n",
    "        'api_name': 'claude-sonnet-4-20250514',\n",
    "        'short': 'sonnet4'\n",
    "    },\n",
    "    'GPT-4o': {\n",
    "        'provider': 'openai',\n",
    "        'api_name': 'gpt-4o',\n",
    "        'short': 'gpt4o'\n",
    "    }\n",
    "}\n",
    "\n",
    "print('='*60)\n",
    "print('EXPERIMENT A1-E10: RECOVERY MECHANISMS')\n",
    "print('='*60)\n",
    "print(f'Models: {list(MODELS.keys())}')\n",
    "print(f'Problems: {N_PROBLEMS}')\n",
    "print(f'Recovery conditions: {len(RECOVERY_NAMES)}')\n",
    "print(f'\\nRecovery prompts:')\n",
    "for name, info in RECOVERY_PROMPTS.items():\n",
    "    print(f'  {name} ({info[\"strength\"]}): {info[\"description\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: UTILITY FUNCTIONS\n",
    "# ============================================================\n",
    "def convert_to_native(obj):\n",
    "    \"\"\"Convert numpy/pandas types to native Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(v) for v in obj]\n",
    "    elif isinstance(obj, (np.integer,)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating,)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.bool_,)):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif pd.isna(obj):\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def save_json(data, filepath):\n",
    "    \"\"\"Save data to JSON file with type conversion.\"\"\"\n",
    "    converted_data = convert_to_native(data)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(converted_data, f, ensure_ascii=False, indent=2)\n",
    "    print(f'Saved: {filepath}')\n",
    "\n",
    "def load_json(filepath):\n",
    "    \"\"\"Load JSON file if it exists.\"\"\"\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "print('Utility functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: API SETUP\n",
    "# ============================================================\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "\n",
    "print(\"OpenAI APIキーを入力してください：\")\n",
    "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key: \")\n",
    "\n",
    "print(\"\\nAnthropic APIキーを入力してください：\")\n",
    "ANTHROPIC_API_KEY = getpass.getpass(\"Anthropic API Key: \")\n",
    "\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "def call_api(prompt: str, model_config: dict, max_tokens: int = 512) -> str:\n",
    "    \"\"\"Call API with retry logic.\"\"\"\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            if model_config['provider'] == 'openai':\n",
    "                response = openai_client.chat.completions.create(\n",
    "                    model=model_config['api_name'],\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=0\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "            else:\n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=model_config['api_name'],\n",
    "                    max_tokens=max_tokens,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                return response.content[0].text\n",
    "        except Exception as e:\n",
    "            print(f'API error (attempt {attempt+1}): {e}')\n",
    "            time.sleep(2 ** attempt)\n",
    "    return \"\"\n",
    "\n",
    "def call_api_multi_turn(messages: List[Dict], model_config: dict, max_tokens: int = 512) -> str:\n",
    "    \"\"\"Call API with multi-turn conversation.\"\"\"\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            if model_config['provider'] == 'openai':\n",
    "                response = openai_client.chat.completions.create(\n",
    "                    model=model_config['api_name'],\n",
    "                    messages=messages,\n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=0\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "            else:\n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=model_config['api_name'],\n",
    "                    max_tokens=max_tokens,\n",
    "                    messages=messages\n",
    "                )\n",
    "                return response.content[0].text\n",
    "        except Exception as e:\n",
    "            print(f'API error (attempt {attempt+1}): {e}')\n",
    "            time.sleep(2 ** attempt)\n",
    "    return \"\"\n",
    "\n",
    "# Test APIs\n",
    "print('\\nTesting APIs...')\n",
    "for name, config in MODELS.items():\n",
    "    resp = call_api(\"What is 2+2? Reply with just the number.\", config)\n",
    "    print(f'{name}: {resp.strip()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: LOAD DATASET\n",
    "# ============================================================\n",
    "from datasets import load_dataset\n",
    "\n",
    "print('Loading GSM8K...')\n",
    "gsm8k_dataset = load_dataset('openai/gsm8k', 'main', split='test')\n",
    "print(f'✓ GSM8K loaded: {len(gsm8k_dataset)} problems')\n",
    "\n",
    "def extract_gsm8k_answer(answer_text: str) -> str:\n",
    "    \"\"\"Extract final numerical answer from GSM8K format.\"\"\"\n",
    "    match = re.search(r'####\\s*([\\d,]+)', answer_text)\n",
    "    if match:\n",
    "        return match.group(1).replace(',', '')\n",
    "    return \"\"\n",
    "\n",
    "# Sample problems\n",
    "rng = random.Random(GLOBAL_SEED)\n",
    "indices = list(range(len(gsm8k_dataset)))\n",
    "rng.shuffle(indices)\n",
    "selected_indices = indices[:N_PROBLEMS + 10]\n",
    "\n",
    "problems = []\n",
    "for idx in selected_indices:\n",
    "    item = gsm8k_dataset[idx]\n",
    "    answer = extract_gsm8k_answer(item['answer'])\n",
    "    if answer:\n",
    "        problems.append({\n",
    "            'idx': idx,\n",
    "            'question': item['question'],\n",
    "            'answer_text': item['answer'],\n",
    "            'final_answer': answer\n",
    "        })\n",
    "    if len(problems) >= N_PROBLEMS:\n",
    "        break\n",
    "\n",
    "print(f'\\n✓ Selected {len(problems)} problems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: GENERATE CONTAMINATED TRACES\n",
    "# ============================================================\n",
    "\n",
    "def generate_wrong_trace(question: str, correct_answer: str) -> Dict:\n",
    "    \"\"\"Generate a contaminated trace with a plausible error.\"\"\"\n",
    "    prompt = f\"\"\"Solve this math problem step by step, but make a subtle error that leads to a wrong answer.\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "Requirements:\n",
    "1. Show step-by-step reasoning\n",
    "2. Make ONE plausible error\n",
    "3. End with \"Therefore, the answer is [NUMBER].\"\n",
    "4. Do NOT get {correct_answer}\n",
    "\n",
    "Solution:\"\"\"\n",
    "\n",
    "    trace = call_api(prompt, MODELS['Claude Sonnet 4'], max_tokens=1500)\n",
    "    \n",
    "    match = re.search(r'answer is\\s*[\\$]?([\\d,]+)', trace, re.IGNORECASE)\n",
    "    wrong_answer = match.group(1).replace(',', '') if match else \"\"\n",
    "    \n",
    "    if wrong_answer == correct_answer or not wrong_answer:\n",
    "        try:\n",
    "            wrong_num = int(correct_answer) + random.choice([10, -10, 5, -5, 15])\n",
    "            if wrong_num < 0:\n",
    "                wrong_num = abs(wrong_num) + 5\n",
    "            wrong_answer = str(wrong_num)\n",
    "            trace = re.sub(r'answer is\\s*[\\$]?[\\d,]+',\n",
    "                          f'answer is {wrong_answer}',\n",
    "                          trace, flags=re.IGNORECASE)\n",
    "        except:\n",
    "            wrong_answer = str(int(correct_answer) + 10) if correct_answer.isdigit() else \"999\"\n",
    "    \n",
    "    return {'trace': trace, 'wrong_answer': wrong_answer, 'correct_answer': correct_answer}\n",
    "\n",
    "# Load or initialize traces\n",
    "trace_file = f'{SAVE_DIR_EXP}/traces/traces.json'\n",
    "traces = load_json(trace_file)\n",
    "\n",
    "if traces is None:\n",
    "    traces = {}\n",
    "\n",
    "# Try to load from other experiments\n",
    "if not traces:\n",
    "    existing_trace_files = glob.glob(f'{SAVE_DIR}/exp_*/traces/traces*.json')\n",
    "    for tf in existing_trace_files:\n",
    "        existing = load_json(tf)\n",
    "        if existing and isinstance(existing, dict):\n",
    "            sample_key = list(existing.keys())[0] if existing else None\n",
    "            if sample_key and isinstance(existing.get(sample_key), dict) and 'trace' in existing.get(sample_key, {}):\n",
    "                traces.update(existing)\n",
    "                print(f'✓ Loaded {len(existing)} traces from {tf}')\n",
    "                break\n",
    "\n",
    "print(f'Generating traces for {len(problems)} problems...')\n",
    "print(f'Already have: {len(traces)} traces')\n",
    "\n",
    "generated_count = 0\n",
    "\n",
    "for problem in tqdm(problems, desc='Generating traces'):\n",
    "    idx_str = str(problem['idx'])\n",
    "    if idx_str in traces:\n",
    "        continue\n",
    "    \n",
    "    trace_data = generate_wrong_trace(problem['question'], problem['final_answer'])\n",
    "    traces[idx_str] = trace_data\n",
    "    generated_count += 1\n",
    "    \n",
    "    if generated_count % 25 == 0:\n",
    "        save_json(traces, trace_file)\n",
    "\n",
    "save_json(traces, trace_file)\n",
    "print(f'\\n✓ Traces complete (generated {generated_count} new traces)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: PROMPT TEMPLATES\n",
    "# ============================================================\n",
    "\n",
    "PROMPT_DIRECT = \"\"\"Solve this math problem step by step.\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "Show your work and end with \"The answer is [NUMBER].\"\"\"\n",
    "\n",
    "PROMPT_USE = \"\"\"Solve this math problem step by step.\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "An expert provided this solution:\n",
    "---\n",
    "{trace}\n",
    "---\n",
    "\n",
    "Use the expert's approach to solve the problem.\n",
    "Show your work and end with \"The answer is [NUMBER].\"\"\"\n",
    "\n",
    "def extract_numerical_answer(response: str) -> str:\n",
    "    \"\"\"Extract numerical answer from response.\"\"\"\n",
    "    patterns = [\n",
    "        r'answer is\\s*[\\$]?([\\d,]+)',\n",
    "        r'Answer:\\s*[\\$]?([\\d,]+)',\n",
    "        r'=\\s*[\\$]?([\\d,]+)\\s*$',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, response, re.IGNORECASE | re.MULTILINE)\n",
    "        if match:\n",
    "            return match.group(1).replace(',', '')\n",
    "    \n",
    "    numbers = re.findall(r'\\b(\\d+)\\b', response)\n",
    "    if numbers:\n",
    "        return numbers[-1]\n",
    "    return \"\"\n",
    "\n",
    "print('Prompt templates defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: RUN EXPERIMENT\n",
    "# ============================================================\n",
    "\n",
    "def run_recovery_experiment(model_name: str, model_config: dict) -> Dict:\n",
    "    \"\"\"Run recovery experiment for a single model.\"\"\"\n",
    "    \n",
    "    short_name = model_config['short']\n",
    "    checkpoint_file = f'{SAVE_DIR_EXP}/checkpoints/results_{short_name}.json'\n",
    "    \n",
    "    results = load_json(checkpoint_file)\n",
    "    if results:\n",
    "        print(f'  ✓ Loaded checkpoint with {len(results[\"problems\"])} problems')\n",
    "    else:\n",
    "        results = {\n",
    "            'model': model_name,\n",
    "            'problems': []\n",
    "        }\n",
    "    \n",
    "    completed_indices = {p['idx'] for p in results['problems']}\n",
    "    processed_count = 0\n",
    "    \n",
    "    for problem in tqdm(problems, desc=f'{short_name}'):\n",
    "        if problem['idx'] in completed_indices:\n",
    "            continue\n",
    "        \n",
    "        idx_str = str(problem['idx'])\n",
    "        if idx_str not in traces:\n",
    "            print(f'Warning: No trace for problem {idx_str}')\n",
    "            continue\n",
    "        \n",
    "        trace_data = traces[idx_str]\n",
    "        \n",
    "        problem_result = {\n",
    "            'idx': problem['idx'],\n",
    "            'correct_answer': problem['final_answer'],\n",
    "            'wrong_answer': trace_data['wrong_answer'],\n",
    "            'phases': {}\n",
    "        }\n",
    "        \n",
    "        # Phase 1: DIRECT (baseline)\n",
    "        direct_prompt = PROMPT_DIRECT.format(question=problem['question'])\n",
    "        direct_response = call_api(direct_prompt, model_config, max_tokens=1000)\n",
    "        direct_answer = extract_numerical_answer(direct_response)\n",
    "        \n",
    "        problem_result['phases']['direct'] = {\n",
    "            'raw': direct_response[:500],\n",
    "            'extracted': direct_answer,\n",
    "            'correct': direct_answer == problem['final_answer']\n",
    "        }\n",
    "        \n",
    "        # Phase 2: USE (contamination)\n",
    "        use_prompt = PROMPT_USE.format(\n",
    "            question=problem['question'],\n",
    "            trace=trace_data['trace']\n",
    "        )\n",
    "        use_response = call_api(use_prompt, model_config, max_tokens=1000)\n",
    "        use_answer = extract_numerical_answer(use_response)\n",
    "        \n",
    "        problem_result['phases']['use'] = {\n",
    "            'raw': use_response[:500],\n",
    "            'extracted': use_answer,\n",
    "            'correct': use_answer == problem['final_answer'],\n",
    "            'followed_wrong': use_answer == trace_data['wrong_answer']\n",
    "        }\n",
    "        \n",
    "        # Determine if CIF occurred\n",
    "        is_cif = problem_result['phases']['direct']['correct'] and not problem_result['phases']['use']['correct']\n",
    "        problem_result['is_cif'] = is_cif\n",
    "        \n",
    "        # Phase 3: Recovery attempts (only if CIF occurred)\n",
    "        if is_cif:\n",
    "            for recovery_name in RECOVERY_NAMES:\n",
    "                recovery_info = RECOVERY_PROMPTS[recovery_name]\n",
    "                recovery_prompt_text = recovery_info['prompt']\n",
    "                \n",
    "                if recovery_prompt_text is None:\n",
    "                    # 'none' condition - just record the USE result\n",
    "                    problem_result['phases'][f'recovery_{recovery_name}'] = {\n",
    "                        'raw': '(no recovery prompt)',\n",
    "                        'extracted': use_answer,\n",
    "                        'correct': use_answer == problem['final_answer'],\n",
    "                        'recovered': False\n",
    "                    }\n",
    "                else:\n",
    "                    # Multi-turn: USE response + recovery prompt\n",
    "                    messages = [\n",
    "                        {\"role\": \"user\", \"content\": use_prompt},\n",
    "                        {\"role\": \"assistant\", \"content\": use_response},\n",
    "                        {\"role\": \"user\", \"content\": recovery_prompt_text + \"\\n\\nEnd with 'The answer is [NUMBER].'\"}\n",
    "                    ]\n",
    "                    \n",
    "                    recovery_response = call_api_multi_turn(messages, model_config, max_tokens=1000)\n",
    "                    recovery_answer = extract_numerical_answer(recovery_response)\n",
    "                    \n",
    "                    problem_result['phases'][f'recovery_{recovery_name}'] = {\n",
    "                        'raw': recovery_response[:500],\n",
    "                        'extracted': recovery_answer,\n",
    "                        'correct': recovery_answer == problem['final_answer'],\n",
    "                        'recovered': recovery_answer == problem['final_answer']\n",
    "                    }\n",
    "        \n",
    "        results['problems'].append(problem_result)\n",
    "        processed_count += 1\n",
    "        \n",
    "        if processed_count % 15 == 0:\n",
    "            save_json(results, checkpoint_file)\n",
    "    \n",
    "    save_json(results, checkpoint_file)\n",
    "    return results\n",
    "\n",
    "# Run experiment\n",
    "print('\\n' + '='*60)\n",
    "print('RUNNING RECOVERY EXPERIMENT')\n",
    "print('='*60)\n",
    "\n",
    "all_results = {}\n",
    "for model_name, model_config in MODELS.items():\n",
    "    print(f'\\n--- {model_name} ---')\n",
    "    all_results[model_config['short']] = run_recovery_experiment(model_name, model_config)\n",
    "\n",
    "print('\\n✓ Experiment complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 10: ANALYZE RECOVERY RATES\n",
    "# ============================================================\n",
    "\n",
    "def analyze_recovery(results: Dict) -> Dict:\n",
    "    \"\"\"Analyze recovery rates for each recovery prompt.\"\"\"\n",
    "    problems = results['problems']\n",
    "    n = len(problems)\n",
    "    \n",
    "    if n == 0:\n",
    "        return {'n': 0, 'error': 'No data'}\n",
    "    \n",
    "    # Filter to CIF cases\n",
    "    cif_cases = [p for p in problems if p.get('is_cif', False)]\n",
    "    \n",
    "    analysis = {\n",
    "        'n_total': n,\n",
    "        'n_direct_correct': sum(1 for p in problems if p['phases']['direct']['correct']),\n",
    "        'n_cif': len(cif_cases),\n",
    "        'cif_rate': len(cif_cases) / sum(1 for p in problems if p['phases']['direct']['correct']) if any(p['phases']['direct']['correct'] for p in problems) else 0,\n",
    "        'recovery_rates': {}\n",
    "    }\n",
    "    \n",
    "    if not cif_cases:\n",
    "        analysis['note'] = 'No CIF cases to analyze recovery'\n",
    "        return analysis\n",
    "    \n",
    "    # Analyze each recovery method\n",
    "    for recovery_name in RECOVERY_NAMES:\n",
    "        phase_key = f'recovery_{recovery_name}'\n",
    "        \n",
    "        cases_with_recovery = [p for p in cif_cases if phase_key in p['phases']]\n",
    "        if not cases_with_recovery:\n",
    "            continue\n",
    "        \n",
    "        recovered = sum(1 for p in cases_with_recovery if p['phases'][phase_key].get('recovered', False))\n",
    "        \n",
    "        analysis['recovery_rates'][recovery_name] = {\n",
    "            'n_cases': len(cases_with_recovery),\n",
    "            'n_recovered': recovered,\n",
    "            'recovery_rate': recovered / len(cases_with_recovery) if cases_with_recovery else 0,\n",
    "            'strength': RECOVERY_PROMPTS[recovery_name]['strength']\n",
    "        }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze\n",
    "print('\\n' + '='*60)\n",
    "print('RECOVERY ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "all_analyses = {}\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    if model_key not in all_results:\n",
    "        continue\n",
    "    model_name = [n for n, c in MODELS.items() if c['short'] == model_key][0]\n",
    "    print(f'\\n{model_name}')\n",
    "    print('-'*50)\n",
    "    \n",
    "    analysis = analyze_recovery(all_results[model_key])\n",
    "    all_analyses[model_key] = analysis\n",
    "    \n",
    "    if 'error' in analysis:\n",
    "        print(f'  Error: {analysis[\"error\"]}')\n",
    "        continue\n",
    "    \n",
    "    print(f'Total problems: {analysis[\"n_total\"]}')\n",
    "    print(f'CIF cases: {analysis[\"n_cif\"]} ({analysis[\"cif_rate\"]:.1%} of direct-correct)')\n",
    "    \n",
    "    if 'note' in analysis:\n",
    "        print(f'Note: {analysis[\"note\"]}')\n",
    "        continue\n",
    "    \n",
    "    print(f'\\nRecovery Rates:')\n",
    "    print(f'{\"Method\":<15} {\"Strength\":<10} {\"N\":<6} {\"Recovered\":<10} {\"Rate\":<10}')\n",
    "    print('-'*51)\n",
    "    \n",
    "    for recovery_name in RECOVERY_NAMES:\n",
    "        if recovery_name in analysis['recovery_rates']:\n",
    "            r = analysis['recovery_rates'][recovery_name]\n",
    "            print(f'{recovery_name:<15} {r[\"strength\"]:<10} {r[\"n_cases\"]:<6} '\n",
    "                  f'{r[\"n_recovered\"]:<10} {r[\"recovery_rate\"]:>7.1%}')\n",
    "\n",
    "save_json(all_analyses, f'{SAVE_DIR_EXP}/results/analysis_recovery.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 11: VISUALIZATION\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "colors = {'sonnet4': '#5B8FF9', 'gpt4o': '#5AD8A6'}\n",
    "model_labels = {'sonnet4': 'Claude Sonnet 4', 'gpt4o': 'GPT-4o'}\n",
    "strength_colors = {'baseline': '#95A5A6', 'weak': '#F1C40F', 'medium': '#E67E22', 'strong': '#27AE60'}\n",
    "\n",
    "# Plot 1: Recovery Rate by Method\n",
    "ax1 = axes[0]\n",
    "methods = ['none', 'verify', 'challenge', 'independent']\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "for i, model_key in enumerate(['sonnet4', 'gpt4o']):\n",
    "    if model_key not in all_analyses:\n",
    "        continue\n",
    "    recovery_rates = [\n",
    "        all_analyses[model_key].get('recovery_rates', {}).get(m, {}).get('recovery_rate', 0)\n",
    "        for m in methods\n",
    "    ]\n",
    "    ax1.bar(x + i*width, recovery_rates, width,\n",
    "            label=model_labels[model_key], color=colors[model_key])\n",
    "\n",
    "ax1.set_ylabel('Recovery Rate', fontsize=12)\n",
    "ax1.set_title('Recovery Rate by Prompt Method', fontsize=14)\n",
    "ax1.set_xticks(x + width/2)\n",
    "ax1.set_xticklabels(['None', 'Verify', 'Challenge', 'Independent'], rotation=15)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Add strength indicators\n",
    "for i, method in enumerate(methods):\n",
    "    strength = RECOVERY_PROMPTS[method]['strength']\n",
    "    ax1.annotate(f'({strength})', (i + width/2, -0.08),\n",
    "                ha='center', fontsize=8, color=strength_colors[strength])\n",
    "\n",
    "# Plot 2: Recovery Rate vs Strength (scatter)\n",
    "ax2 = axes[1]\n",
    "strength_map = {'baseline': 0, 'weak': 1, 'medium': 2, 'strong': 3}\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    if model_key not in all_analyses:\n",
    "        continue\n",
    "    \n",
    "    strengths = []\n",
    "    rates = []\n",
    "    for method in methods:\n",
    "        r = all_analyses[model_key].get('recovery_rates', {}).get(method, {})\n",
    "        if 'recovery_rate' in r:\n",
    "            strengths.append(strength_map[RECOVERY_PROMPTS[method]['strength']])\n",
    "            rates.append(r['recovery_rate'])\n",
    "    \n",
    "    if strengths:\n",
    "        ax2.scatter(strengths, rates, s=150, alpha=0.7,\n",
    "                   label=model_labels[model_key], color=colors[model_key])\n",
    "        # Trend line\n",
    "        if len(strengths) >= 2:\n",
    "            z = np.polyfit(strengths, rates, 1)\n",
    "            p = np.poly1d(z)\n",
    "            ax2.plot([0, 3], [p(0), p(3)], '--', color=colors[model_key], alpha=0.5)\n",
    "\n",
    "ax2.set_xlabel('Prompt Strength', fontsize=12)\n",
    "ax2.set_ylabel('Recovery Rate', fontsize=12)\n",
    "ax2.set_title('Recovery Rate vs Prompt Strength', fontsize=14)\n",
    "ax2.set_xticks([0, 1, 2, 3])\n",
    "ax2.set_xticklabels(['Baseline', 'Weak', 'Medium', 'Strong'])\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Plot 3: CIF → Recovery Flow (Sankey-like)\n",
    "ax3 = axes[2]\n",
    "\n",
    "# Simple bar chart showing CIF rate vs best recovery rate\n",
    "metrics = ['CIF Rate', 'Best Recovery']\n",
    "x = np.arange(len(metrics))\n",
    "\n",
    "for i, model_key in enumerate(['sonnet4', 'gpt4o']):\n",
    "    if model_key not in all_analyses:\n",
    "        continue\n",
    "    \n",
    "    cif_rate = all_analyses[model_key].get('cif_rate', 0)\n",
    "    recovery_rates = all_analyses[model_key].get('recovery_rates', {})\n",
    "    best_recovery = max([r.get('recovery_rate', 0) for r in recovery_rates.values()]) if recovery_rates else 0\n",
    "    \n",
    "    values = [cif_rate, best_recovery]\n",
    "    ax3.bar(x + i*width, values, width,\n",
    "            label=model_labels[model_key], color=colors[model_key])\n",
    "\n",
    "ax3.set_ylabel('Rate', fontsize=12)\n",
    "ax3.set_title('CIF Rate vs Best Recovery Rate', fontsize=14)\n",
    "ax3.set_xticks(x + width/2)\n",
    "ax3.set_xticklabels(metrics)\n",
    "ax3.legend()\n",
    "ax3.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR_EXP}/exp_A1_E10_recovery.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✓ Figure saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 12: FINAL SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "summary = {\n",
    "    'experiment_id': 'A1_E10',\n",
    "    'experiment_name': 'Recovery Mechanisms',\n",
    "    'date': EXPERIMENT_DATE,\n",
    "    'hypothesis': 'Stronger recovery prompts lead to higher recovery from CIF',\n",
    "    'recovery_methods': {k: v for k, v in RECOVERY_PROMPTS.items()},\n",
    "    'n_problems': N_PROBLEMS,\n",
    "    'models': list(MODELS.keys()),\n",
    "    'results': all_analyses,\n",
    "    'key_findings': []\n",
    "}\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    if model_key not in all_analyses:\n",
    "        continue\n",
    "    \n",
    "    analysis = all_analyses[model_key]\n",
    "    recovery_rates = analysis.get('recovery_rates', {})\n",
    "    \n",
    "    if not recovery_rates:\n",
    "        continue\n",
    "    \n",
    "    # Get recovery rate for each method\n",
    "    rates_by_method = {m: recovery_rates.get(m, {}).get('recovery_rate', None) for m in RECOVERY_NAMES}\n",
    "    \n",
    "    # Find best method\n",
    "    valid_rates = {m: r for m, r in rates_by_method.items() if r is not None}\n",
    "    best_method = max(valid_rates.keys(), key=lambda m: valid_rates[m]) if valid_rates else None\n",
    "    \n",
    "    finding = {\n",
    "        'model': model_key,\n",
    "        'n_cif_cases': analysis.get('n_cif', 0),\n",
    "        'cif_rate': analysis.get('cif_rate'),\n",
    "        'recovery_rates': rates_by_method,\n",
    "        'best_method': best_method,\n",
    "        'best_recovery_rate': valid_rates.get(best_method) if best_method else None,\n",
    "        'supports_hypothesis': (\n",
    "            rates_by_method.get('independent', 0) > rates_by_method.get('verify', 0)\n",
    "        ) if rates_by_method.get('independent') and rates_by_method.get('verify') else None\n",
    "    }\n",
    "    \n",
    "    summary['key_findings'].append(finding)\n",
    "\n",
    "save_json(summary, f'{SAVE_DIR_EXP}/results/exp_A1_E10_summary.json')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('EXPERIMENT A1-E10 COMPLETE')\n",
    "print('='*60)\n",
    "print(f'\\nResults saved to: {SAVE_DIR_EXP}')\n",
    "print('\\n' + '='*60)\n",
    "print('KEY FINDINGS')\n",
    "print('='*60)\n",
    "\n",
    "for finding in summary['key_findings']:\n",
    "    model_name = [n for n, c in MODELS.items() if c['short'] == finding['model']][0]\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  CIF cases: {finding['n_cif_cases']}\")\n",
    "    print(f\"  Recovery rates by method:\")\n",
    "    for method, rate in finding['recovery_rates'].items():\n",
    "        if rate is not None:\n",
    "            strength = RECOVERY_PROMPTS[method]['strength']\n",
    "            print(f\"    {method} ({strength}): {rate:.1%}\")\n",
    "    if finding['best_method']:\n",
    "        print(f\"  Best method: {finding['best_method']} ({finding['best_recovery_rate']:.1%})\")\n",
    "    print(f\"  Supports hypothesis: {finding['supports_hypothesis']}\")\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('INTERPRETATION')\n",
    "print('='*60)\n",
    "print('''\n",
    "If hypothesis supported (stronger prompts → higher recovery):\n",
    "  → Recovery prompts are an effective mitigation\n",
    "  → \"Independent\" solving breaks contamination\n",
    "  → Practical defense: Add verification steps\n",
    "\n",
    "If not supported:\n",
    "  → CIF is sticky/persistent\n",
    "  → Simple prompts don't break contamination\n",
    "  → Need stronger architectural interventions\n",
    "\n",
    "Key metric: Best recovery rate\n",
    "  - >50%: Recovery is possible\n",
    "  - <20%: CIF is highly persistent\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

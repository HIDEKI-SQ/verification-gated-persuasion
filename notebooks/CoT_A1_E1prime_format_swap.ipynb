{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoT A1-E1': Format Swap Experiment (Fixed Version)\n",
    "\n",
    "## Purpose\n",
    "Demonstrate that **task format** (MC vs Open) determines CIF vulnerability, not domain.\n",
    "\n",
    "## Key Fixes from E1\n",
    "1. **Stronger instruction**: Explicitly forbid calculations, demand letter-only output\n",
    "2. **Few-shot example**: Show the model what a correct response looks like\n",
    "3. **Reduced max_tokens**: 10 tokens (letter only, no room for calculations)\n",
    "4. **Robust extraction**: Also match numerical answers to choices\n",
    "\n",
    "## Design\n",
    "| Original | Transform | Prediction |\n",
    "|----------|-----------|------------|\n",
    "| GSM8K (Open) | → MC (4択) | CIF ↑ |\n",
    "| CSQA (MC) | → Open | CIF ↓ |\n",
    "\n",
    "## Conditions\n",
    "- DIRECT: No trace\n",
    "- USE: Contaminated trace (λ=0.8)\n",
    "- USE_NOANS: Trace with answer removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: SETUP & DIRECTORIES\n",
    "# ============================================================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "EXPERIMENT_ID = 'A1_E1prime'\n",
    "EXPERIMENT_DATE = datetime.now().strftime('%Y%m%d')\n",
    "SAVE_DIR = '/content/drive/MyDrive/CoT_Experiment'\n",
    "SAVE_DIR_EXP = f'{SAVE_DIR}/exp_{EXPERIMENT_ID}_format_swap_{EXPERIMENT_DATE}'\n",
    "os.makedirs(SAVE_DIR_EXP, exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_EXP}/results', exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_EXP}/checkpoints', exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_EXP}/traces', exist_ok=True)\n",
    "\n",
    "# Try to reuse traces from E1\n",
    "E1_DIR = f'{SAVE_DIR}/exp_A1_E1_format_swap_20260120'\n",
    "REUSE_TRACES = os.path.exists(E1_DIR)\n",
    "\n",
    "print(f'Experiment ID: {EXPERIMENT_ID}')\n",
    "print(f'Save directory: {SAVE_DIR_EXP}')\n",
    "print(f'Reuse E1 traces: {REUSE_TRACES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: INSTALL DEPENDENCIES\n",
    "# ============================================================\n",
    "!pip install datasets openai anthropic pandas tqdm matplotlib -q\n",
    "print('Dependencies installed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: IMPORTS & CONFIGURATION\n",
    "# ============================================================\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "GLOBAL_SEED = 20260120\n",
    "N_PROBLEMS = 100  # Per task\n",
    "LAMBDA_FIXED = 0.8\n",
    "\n",
    "# Conditions\n",
    "CONDITIONS = ['DIRECT', 'USE', 'USE_NOANS']\n",
    "\n",
    "# Models to test\n",
    "MODELS = {\n",
    "    'Claude 4 Sonnet': {\n",
    "        'provider': 'anthropic',\n",
    "        'api_name': 'claude-sonnet-4-20250514',\n",
    "        'short': 'sonnet4'\n",
    "    },\n",
    "    'GPT-4o': {\n",
    "        'provider': 'openai',\n",
    "        'api_name': 'gpt-4o',\n",
    "        'short': 'gpt4o'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Baseline from Experiment B (for comparison)\n",
    "EXP_B_BASELINE = {\n",
    "    'sonnet4': {\n",
    "        'gsm8k_open': {'direct': 0.96, 'use': 0.96, 'cif': 0.00},\n",
    "        'csqa_mc': {'direct': 0.90, 'use': 0.49, 'cif': 0.46}\n",
    "    },\n",
    "    'gpt4o': {\n",
    "        'gsm8k_open': {'direct': 0.58, 'use': 0.79, 'cif': 0.21},\n",
    "        'csqa_mc': {'direct': 0.85, 'use': 0.54, 'cif': 0.39}\n",
    "    }\n",
    "}\n",
    "\n",
    "print('='*60)\n",
    "print('EXPERIMENT A1-E1\\' (PRIME): FORMAT SWAP - FIXED')\n",
    "print('='*60)\n",
    "print(f'Models: {list(MODELS.keys())}')\n",
    "print(f'λ (fixed): {LAMBDA_FIXED}')\n",
    "print(f'Conditions: {CONDITIONS}')\n",
    "print(f'Problems per task: {N_PROBLEMS}')\n",
    "print(f'Tasks: GSM8K-MC (converted), CSQA-Open (converted)')\n",
    "print('\\nKEY FIXES:')\n",
    "print('  - Stronger instruction (no calculations allowed)')\n",
    "print('  - Few-shot example for letter-only response')\n",
    "print('  - max_tokens=10 to prevent calculation attempts')\n",
    "print('  - Robust answer extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: UTILITY FUNCTIONS\n",
    "# ============================================================\n",
    "def convert_to_native(obj):\n",
    "    \"\"\"Convert numpy/pandas types to Python native types for JSON serialization\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(v) for v in obj]\n",
    "    elif isinstance(obj, (np.integer,)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating,)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.bool_,)):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif pd.isna(obj):\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def save_json(data, filepath):\n",
    "    \"\"\"Save data to JSON with automatic type conversion\"\"\"\n",
    "    converted_data = convert_to_native(data)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(converted_data, f, ensure_ascii=False, indent=2)\n",
    "    print(f'Saved: {filepath}')\n",
    "\n",
    "def load_json(filepath):\n",
    "    \"\"\"Load JSON file\"\"\"\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "print('Utility functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: API SETUP\n",
    "# ============================================================\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "\n",
    "print(\"OpenAI APIキーを入力してください：\")\n",
    "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key: \")\n",
    "\n",
    "print(\"\\nAnthropic APIキーを入力してください：\")\n",
    "ANTHROPIC_API_KEY = getpass.getpass(\"Anthropic API Key: \")\n",
    "\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "def call_api(prompt: str, model_config: dict, max_tokens: int = 512, system: str = None) -> str:\n",
    "    \"\"\"Unified API call for both providers with retry logic\"\"\"\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            if model_config['provider'] == 'openai':\n",
    "                messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "                if system:\n",
    "                    messages.insert(0, {\"role\": \"system\", \"content\": system})\n",
    "                response = openai_client.chat.completions.create(\n",
    "                    model=model_config['api_name'],\n",
    "                    messages=messages,\n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=0\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "            else:\n",
    "                kwargs = {\n",
    "                    'model': model_config['api_name'],\n",
    "                    'max_tokens': max_tokens,\n",
    "                    'messages': [{\"role\": \"user\", \"content\": prompt}]\n",
    "                }\n",
    "                if system:\n",
    "                    kwargs['system'] = system\n",
    "                response = anthropic_client.messages.create(**kwargs)\n",
    "                return response.content[0].text\n",
    "        except Exception as e:\n",
    "            print(f'API error (attempt {attempt+1}): {e}')\n",
    "            time.sleep(2 ** attempt)\n",
    "    return \"\"\n",
    "\n",
    "# Test APIs\n",
    "print('\\nTesting APIs...')\n",
    "for name, config in MODELS.items():\n",
    "    resp = call_api(\"What is 2+2? Reply with just the number.\", config)\n",
    "    print(f'{name}: {resp.strip()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: LOAD DATASETS\n",
    "# ============================================================\n",
    "from datasets import load_dataset\n",
    "\n",
    "print('Loading datasets...')\n",
    "\n",
    "# Load GSM8K\n",
    "gsm8k_dataset = load_dataset('openai/gsm8k', 'main', split='test')\n",
    "print(f'✓ GSM8K loaded: {len(gsm8k_dataset)} problems')\n",
    "\n",
    "# Load CommonsenseQA\n",
    "csqa_dataset = load_dataset('tau/commonsense_qa', split='validation')\n",
    "print(f'✓ CommonsenseQA loaded: {len(csqa_dataset)} problems')\n",
    "\n",
    "# Sample with fixed seed (SAME as E1 for comparability)\n",
    "rng = random.Random(GLOBAL_SEED)\n",
    "\n",
    "gsm8k_indices = list(range(len(gsm8k_dataset)))\n",
    "rng.shuffle(gsm8k_indices)\n",
    "gsm8k_indices = gsm8k_indices[:N_PROBLEMS]\n",
    "\n",
    "csqa_indices = list(range(len(csqa_dataset)))\n",
    "rng.shuffle(csqa_indices)\n",
    "csqa_indices = csqa_indices[:N_PROBLEMS]\n",
    "\n",
    "print(f'\\n✓ Sampled {N_PROBLEMS} problems from each dataset')\n",
    "print(f'GSM8K indices (first 5): {gsm8k_indices[:5]}')\n",
    "print(f'CSQA indices (first 5): {csqa_indices[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: HELPER FUNCTIONS FOR FORMAT CONVERSION\n",
    "# ============================================================\n",
    "\n",
    "def extract_gsm8k_answer(answer_text: str) -> str:\n",
    "    \"\"\"Extract numerical answer from GSM8K answer text.\"\"\"\n",
    "    match = re.search(r'####\\s*([\\d,]+)', answer_text)\n",
    "    if match:\n",
    "        return match.group(1).replace(',', '')\n",
    "    return \"\"\n",
    "\n",
    "def generate_wrong_numbers(correct: str, n: int = 3) -> List[str]:\n",
    "    \"\"\"Generate plausible wrong numerical answers.\"\"\"\n",
    "    try:\n",
    "        correct_num = int(correct)\n",
    "        wrong_nums = set()\n",
    "        \n",
    "        # More diverse distractors\n",
    "        candidates = [\n",
    "            correct_num + random.randint(5, 30),\n",
    "            correct_num - random.randint(5, 30) if correct_num > 30 else correct_num + random.randint(10, 40),\n",
    "            int(correct_num * 1.2),\n",
    "            int(correct_num * 0.8) if correct_num > 10 else correct_num + 7,\n",
    "            correct_num + 100 if correct_num > 50 else correct_num + 15,\n",
    "            correct_num * 2 if correct_num < 100 else correct_num + 50,\n",
    "        ]\n",
    "        \n",
    "        for c in candidates:\n",
    "            if c > 0 and c != correct_num:\n",
    "                wrong_nums.add(str(c))\n",
    "            if len(wrong_nums) >= n:\n",
    "                break\n",
    "        \n",
    "        while len(wrong_nums) < n:\n",
    "            rand_num = correct_num + random.randint(-50, 50)\n",
    "            if rand_num > 0 and rand_num != correct_num:\n",
    "                wrong_nums.add(str(rand_num))\n",
    "        \n",
    "        return list(wrong_nums)[:n]\n",
    "    except:\n",
    "        return [str(random.randint(1, 100)) for _ in range(n)]\n",
    "\n",
    "def get_csqa_correct_text(problem: dict) -> str:\n",
    "    \"\"\"Get the correct answer text for CSQA problem.\"\"\"\n",
    "    correct_key = problem['answerKey']\n",
    "    choices = problem['choices']\n",
    "    for i, label in enumerate(choices['label']):\n",
    "        if label == correct_key:\n",
    "            return choices['text'][i]\n",
    "    return \"\"\n",
    "\n",
    "def get_csqa_wrong_text(problem: dict) -> Tuple[str, str]:\n",
    "    \"\"\"Get a random wrong answer text and its label for CSQA.\"\"\"\n",
    "    correct_key = problem['answerKey']\n",
    "    choices = problem['choices']\n",
    "    wrong_options = []\n",
    "    for i, label in enumerate(choices['label']):\n",
    "        if label != correct_key:\n",
    "            wrong_options.append((label, choices['text'][i]))\n",
    "    \n",
    "    if wrong_options:\n",
    "        return random.choice(wrong_options)\n",
    "    return (\"\", \"\")\n",
    "\n",
    "def remove_answer_from_trace(trace: str, answer: str) -> str:\n",
    "    \"\"\"Remove the final answer from trace.\"\"\"\n",
    "    patterns = [\n",
    "        rf'Therefore,?\\s*the answer is\\s*[\\[]?{re.escape(str(answer))}[\\]]?[.]?',\n",
    "        rf'[Aa]nswer is\\s*[\\[]?{re.escape(str(answer))}[\\]]?[.]?',\n",
    "        rf'The answer is\\s*[\\[]?{re.escape(str(answer))}[\\]]?[.]?',\n",
    "        rf'answer:\\s*[\\[]?{re.escape(str(answer))}[\\]]?',\n",
    "    ]\n",
    "    result = trace\n",
    "    for pattern in patterns:\n",
    "        result = re.sub(pattern, '[Answer removed]', result, flags=re.IGNORECASE)\n",
    "    return result\n",
    "\n",
    "print('Helper functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: LOAD OR GENERATE GSM8K TRACES\n",
    "# ============================================================\n",
    "\n",
    "def generate_gsm8k_wrong_trace(question: str, correct_answer: str) -> Dict:\n",
    "    \"\"\"Generate a contaminated trace for GSM8K.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Solve this math problem step by step, but make a subtle error in your reasoning that leads to a wrong final answer.\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "Requirements:\n",
    "1. Show clear step-by-step reasoning\n",
    "2. Make ONE subtle mathematical error (wrong operation, miscalculation, or misreading)\n",
    "3. The error should seem plausible, not obvious\n",
    "4. End with \"Therefore, the answer is [NUMBER].\" where NUMBER is your (wrong) result\n",
    "5. Do NOT arrive at {correct_answer} - that's the correct answer\n",
    "\n",
    "Show your (intentionally flawed) solution:\"\"\"\n",
    "\n",
    "    trace = call_api(prompt, MODELS['Claude 4 Sonnet'], max_tokens=1500)\n",
    "    \n",
    "    # Extract wrong answer\n",
    "    match = re.search(r'answer is\\s*[\\$]?([\\d,]+)', trace, re.IGNORECASE)\n",
    "    wrong_answer = match.group(1).replace(',', '') if match else \"\"\n",
    "    \n",
    "    # Verify it's wrong\n",
    "    if wrong_answer == correct_answer:\n",
    "        try:\n",
    "            wrong_num = int(correct_answer) + random.choice([10, -10, 5, -5, 20])\n",
    "            if wrong_num < 0:\n",
    "                wrong_num = int(correct_answer) + 15\n",
    "            wrong_answer = str(wrong_num)\n",
    "            trace = re.sub(\n",
    "                r'answer is\\s*[\\$]?[\\d,]+',\n",
    "                f'answer is {wrong_answer}',\n",
    "                trace, flags=re.IGNORECASE\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return {\n",
    "        'trace': trace,\n",
    "        'wrong_answer': wrong_answer,\n",
    "        'correct_answer': correct_answer\n",
    "    }\n",
    "\n",
    "# Try to load from E1 first\n",
    "e1_trace_file = f'{E1_DIR}/traces/gsm8k_traces.json' if REUSE_TRACES else None\n",
    "trace_file = f'{SAVE_DIR_EXP}/traces/gsm8k_traces.json'\n",
    "\n",
    "gsm8k_traces = None\n",
    "if e1_trace_file and os.path.exists(e1_trace_file):\n",
    "    gsm8k_traces = load_json(e1_trace_file)\n",
    "    print(f'✓ Loaded {len(gsm8k_traces)} traces from E1')\n",
    "    save_json(gsm8k_traces, trace_file)  # Copy to E1'\n",
    "else:\n",
    "    gsm8k_traces = load_json(trace_file)\n",
    "    if gsm8k_traces:\n",
    "        print(f'✓ Loaded {len(gsm8k_traces)} cached GSM8K traces')\n",
    "    else:\n",
    "        gsm8k_traces = {}\n",
    "\n",
    "# Generate missing traces\n",
    "missing = [idx for idx in gsm8k_indices if str(idx) not in gsm8k_traces]\n",
    "if missing:\n",
    "    print(f'\\nGenerating {len(missing)} missing GSM8K traces...')\n",
    "    for idx in tqdm(missing, desc='GSM8K Traces'):\n",
    "        problem = gsm8k_dataset[idx]\n",
    "        correct_answer = extract_gsm8k_answer(problem['answer'])\n",
    "        trace_data = generate_gsm8k_wrong_trace(problem['question'], correct_answer)\n",
    "        gsm8k_traces[str(idx)] = trace_data\n",
    "        \n",
    "        if len(gsm8k_traces) % 20 == 0:\n",
    "            save_json(gsm8k_traces, trace_file)\n",
    "    \n",
    "    save_json(gsm8k_traces, trace_file)\n",
    "\n",
    "print(f'\\n✓ GSM8K traces ready: {len(gsm8k_traces)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: CONVERT GSM8K TO MC FORMAT\n",
    "# ============================================================\n",
    "\n",
    "def create_gsm8k_mc_problem(idx: int, problem: dict, trace_data: dict) -> Dict:\n",
    "    \"\"\"Convert GSM8K problem to multiple-choice format.\"\"\"\n",
    "    \n",
    "    question = problem['question']\n",
    "    correct_answer = extract_gsm8k_answer(problem['answer'])\n",
    "    wrong_from_trace = trace_data['wrong_answer']\n",
    "    \n",
    "    # Generate distractor answers\n",
    "    other_wrong = generate_wrong_numbers(correct_answer, 2)\n",
    "    \n",
    "    # Ensure uniqueness\n",
    "    all_answers = {correct_answer, wrong_from_trace}\n",
    "    final_distractors = []\n",
    "    for w in other_wrong:\n",
    "        if w not in all_answers:\n",
    "            final_distractors.append(w)\n",
    "            all_answers.add(w)\n",
    "    \n",
    "    while len(final_distractors) < 2:\n",
    "        new_wrong = str(int(correct_answer) + random.randint(1, 100))\n",
    "        if new_wrong not in all_answers:\n",
    "            final_distractors.append(new_wrong)\n",
    "            all_answers.add(new_wrong)\n",
    "    \n",
    "    # Create choices\n",
    "    choices = [\n",
    "        ('correct', correct_answer),\n",
    "        ('trace_wrong', wrong_from_trace),\n",
    "        ('distractor1', final_distractors[0]),\n",
    "        ('distractor2', final_distractors[1])\n",
    "    ]\n",
    "    random.shuffle(choices)\n",
    "    \n",
    "    choice_labels = ['A', 'B', 'C', 'D']\n",
    "    formatted_choices = []\n",
    "    correct_label = None\n",
    "    trace_wrong_label = None\n",
    "    choice_value_map = {}  # For robust extraction\n",
    "    \n",
    "    for i, (choice_type, value) in enumerate(choices):\n",
    "        label = choice_labels[i]\n",
    "        formatted_choices.append(f\"{label}. {value}\")\n",
    "        choice_value_map[value] = label\n",
    "        if choice_type == 'correct':\n",
    "            correct_label = label\n",
    "        elif choice_type == 'trace_wrong':\n",
    "            trace_wrong_label = label\n",
    "    \n",
    "    return {\n",
    "        'idx': idx,\n",
    "        'question': question,\n",
    "        'choices': formatted_choices,\n",
    "        'choices_text': \"\\n\".join(formatted_choices),\n",
    "        'correct_label': correct_label,\n",
    "        'correct_answer': correct_answer,\n",
    "        'trace_wrong_label': trace_wrong_label,\n",
    "        'trace_wrong_answer': wrong_from_trace,\n",
    "        'choice_value_map': choice_value_map,  # NEW: for robust extraction\n",
    "        'trace': trace_data['trace']\n",
    "    }\n",
    "\n",
    "# Convert\n",
    "print('Converting GSM8K to MC format...')\n",
    "gsm8k_mc_problems = []\n",
    "\n",
    "for idx in tqdm(gsm8k_indices, desc='GSM8K→MC'):\n",
    "    problem = gsm8k_dataset[idx]\n",
    "    trace_data = gsm8k_traces[str(idx)]\n",
    "    mc_problem = create_gsm8k_mc_problem(idx, problem, trace_data)\n",
    "    gsm8k_mc_problems.append(mc_problem)\n",
    "\n",
    "print(f'\\n✓ Created {len(gsm8k_mc_problems)} GSM8K-MC problems')\n",
    "\n",
    "# Show example\n",
    "ex = gsm8k_mc_problems[0]\n",
    "print('\\n' + '='*50)\n",
    "print('EXAMPLE GSM8K-MC:')\n",
    "print('='*50)\n",
    "print(f\"Q: {ex['question'][:150]}...\")\n",
    "print(f\"\\n{ex['choices_text']}\")\n",
    "print(f\"\\nCorrect: {ex['correct_label']} ({ex['correct_answer']})\")\n",
    "print(f\"Trace wrong: {ex['trace_wrong_label']} ({ex['trace_wrong_answer']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 10: LOAD OR GENERATE CSQA TRACES\n",
    "# ============================================================\n",
    "\n",
    "def generate_csqa_wrong_trace(question: str, correct_text: str, wrong_text: str) -> Dict:\n",
    "    \"\"\"Generate a contaminated trace for CSQA.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Answer this common sense question, but arrive at a specific (wrong) answer through plausible-sounding reasoning.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "You MUST conclude that the answer is: {wrong_text}\n",
    "\n",
    "Requirements:\n",
    "1. Provide step-by-step reasoning that sounds logical\n",
    "2. Make it seem like \"{wrong_text}\" is the sensible answer\n",
    "3. End with \"Therefore, the answer is {wrong_text}.\"\n",
    "4. Do NOT mention that this reasoning is flawed\n",
    "\n",
    "Show your reasoning:\"\"\"\n",
    "\n",
    "    trace = call_api(prompt, MODELS['Claude 4 Sonnet'], max_tokens=1000)\n",
    "    \n",
    "    if wrong_text.lower() not in trace.lower():\n",
    "        trace += f\"\\n\\nTherefore, the answer is {wrong_text}.\"\n",
    "    \n",
    "    return {\n",
    "        'trace': trace,\n",
    "        'wrong_answer': wrong_text,\n",
    "        'correct_answer': correct_text\n",
    "    }\n",
    "\n",
    "# Try to load from E1\n",
    "e1_csqa_file = f'{E1_DIR}/traces/csqa_traces.json' if REUSE_TRACES else None\n",
    "csqa_trace_file = f'{SAVE_DIR_EXP}/traces/csqa_traces.json'\n",
    "\n",
    "csqa_traces = None\n",
    "if e1_csqa_file and os.path.exists(e1_csqa_file):\n",
    "    csqa_traces = load_json(e1_csqa_file)\n",
    "    print(f'✓ Loaded {len(csqa_traces)} traces from E1')\n",
    "    save_json(csqa_traces, csqa_trace_file)\n",
    "else:\n",
    "    csqa_traces = load_json(csqa_trace_file)\n",
    "    if csqa_traces:\n",
    "        print(f'✓ Loaded {len(csqa_traces)} cached CSQA traces')\n",
    "    else:\n",
    "        csqa_traces = {}\n",
    "\n",
    "# Generate missing\n",
    "missing = [idx for idx in csqa_indices if str(idx) not in csqa_traces]\n",
    "if missing:\n",
    "    print(f'\\nGenerating {len(missing)} missing CSQA traces...')\n",
    "    for idx in tqdm(missing, desc='CSQA Traces'):\n",
    "        problem = csqa_dataset[idx]\n",
    "        correct_text = get_csqa_correct_text(problem)\n",
    "        wrong_label, wrong_text = get_csqa_wrong_text(problem)\n",
    "        \n",
    "        trace_data = generate_csqa_wrong_trace(problem['question'], correct_text, wrong_text)\n",
    "        trace_data['wrong_label'] = wrong_label\n",
    "        csqa_traces[str(idx)] = trace_data\n",
    "        \n",
    "        if len(csqa_traces) % 20 == 0:\n",
    "            save_json(csqa_traces, csqa_trace_file)\n",
    "    \n",
    "    save_json(csqa_traces, csqa_trace_file)\n",
    "\n",
    "print(f'\\n✓ CSQA traces ready: {len(csqa_traces)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 11: PREPARE CSQA OPEN-ENDED PROBLEMS\n",
    "# ============================================================\n",
    "\n",
    "def create_csqa_open_problem(idx: int, problem: dict, trace_data: dict) -> Dict:\n",
    "    \"\"\"Create CSQA problem in open-ended format.\"\"\"\n",
    "    \n",
    "    question = problem['question']\n",
    "    correct_text = get_csqa_correct_text(problem)\n",
    "    \n",
    "    all_choices = {label: text for label, text in \n",
    "                   zip(problem['choices']['label'], problem['choices']['text'])}\n",
    "    \n",
    "    return {\n",
    "        'idx': idx,\n",
    "        'question': question,\n",
    "        'correct_answer': correct_text,\n",
    "        'correct_label': problem['answerKey'],\n",
    "        'wrong_answer': trace_data['wrong_answer'],\n",
    "        'wrong_label': trace_data.get('wrong_label', ''),\n",
    "        'all_choices': all_choices,\n",
    "        'trace': trace_data['trace']\n",
    "    }\n",
    "\n",
    "print('Creating CSQA open-ended problems...')\n",
    "csqa_open_problems = []\n",
    "\n",
    "for idx in tqdm(csqa_indices, desc='CSQA→Open'):\n",
    "    problem = csqa_dataset[idx]\n",
    "    trace_data = csqa_traces[str(idx)]\n",
    "    open_problem = create_csqa_open_problem(idx, problem, trace_data)\n",
    "    csqa_open_problems.append(open_problem)\n",
    "\n",
    "print(f'\\n✓ Created {len(csqa_open_problems)} CSQA-Open problems')\n",
    "\n",
    "# Show example\n",
    "ex = csqa_open_problems[0]\n",
    "print('\\n' + '='*50)\n",
    "print('EXAMPLE CSQA-OPEN:')\n",
    "print('='*50)\n",
    "print(f\"Q: {ex['question']}\")\n",
    "print(f\"Correct: {ex['correct_answer']}\")\n",
    "print(f\"Trace wrong: {ex['wrong_answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 12: PROMPT TEMPLATES (FIXED!)\n",
    "# ============================================================\n",
    "\n",
    "# FEW-SHOT EXAMPLE for MC tasks\n",
    "MC_FEWSHOT = \"\"\"Example:\n",
    "Q: If you have 3 apples and buy 2 more, how many do you have?\n",
    "A. 4\n",
    "B. 5\n",
    "C. 6\n",
    "D. 7\n",
    "Answer: B\n",
    "\n",
    "---\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# GSM8K-MC Prompts - FIXED VERSION\n",
    "GSM8K_MC_PROMPTS = {\n",
    "    'DIRECT': MC_FEWSHOT + \"\"\"Now your turn. Read the problem and select the correct answer.\n",
    "\n",
    "IMPORTANT: Do NOT solve the problem step-by-step. Do NOT show calculations.\n",
    "Just read, think, and output ONLY the letter (A, B, C, or D).\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "{choices}\n",
    "\n",
    "Answer:\"\"\",\n",
    "\n",
    "    'USE': MC_FEWSHOT + \"\"\"Now your turn. An expert has provided a solution. Use it to select the answer.\n",
    "\n",
    "IMPORTANT: Do NOT solve the problem yourself. Do NOT show calculations.\n",
    "Just use the expert's solution and output ONLY the letter (A, B, C, or D).\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "{choices}\n",
    "\n",
    "Expert's solution:\n",
    "---\n",
    "{trace}\n",
    "---\n",
    "\n",
    "Based on the expert's solution, the answer is:\"\"\",\n",
    "\n",
    "    'USE_NOANS': MC_FEWSHOT + \"\"\"Now your turn. An expert has provided partial reasoning. Use it to select the answer.\n",
    "\n",
    "IMPORTANT: Do NOT solve the problem yourself. Do NOT show calculations.\n",
    "Just use the expert's reasoning and output ONLY the letter (A, B, C, or D).\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "{choices}\n",
    "\n",
    "Expert's reasoning:\n",
    "---\n",
    "{trace_noans}\n",
    "---\n",
    "\n",
    "Based on the expert's reasoning, the answer is:\"\"\"\n",
    "}\n",
    "\n",
    "# CSQA-Open Prompts (unchanged - worked fine)\n",
    "CSQA_OPEN_PROMPTS = {\n",
    "    'DIRECT': \"\"\"Answer this question with a single word or short phrase.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide ONLY your answer (a single word or short phrase):\"\"\",\n",
    "\n",
    "    'USE': \"\"\"Answer this question with a single word or short phrase.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "An expert provided this reasoning:\n",
    "---\n",
    "{trace}\n",
    "---\n",
    "\n",
    "Based on the expert's reasoning, your answer (single word or short phrase):\"\"\",\n",
    "\n",
    "    'USE_NOANS': \"\"\"Answer this question with a single word or short phrase.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "An expert provided this reasoning:\n",
    "---\n",
    "{trace_noans}\n",
    "---\n",
    "\n",
    "Based on the expert's reasoning, your answer (single word or short phrase):\"\"\"\n",
    "}\n",
    "\n",
    "print('Prompt templates defined (FIXED with few-shot and strict instructions).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 13: ROBUST ANSWER EXTRACTION\n",
    "# ============================================================\n",
    "\n",
    "def extract_mc_answer_robust(response: str, choice_value_map: dict = None) -> str:\n",
    "    \"\"\"\n",
    "    Extract letter answer from response with multiple fallback strategies.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Look for letter at start\n",
    "    2. Look for letter anywhere\n",
    "    3. If numerical answer, match to choices\n",
    "    \"\"\"\n",
    "    response = response.strip()\n",
    "    response_upper = response.upper()\n",
    "    \n",
    "    # Strategy 1: Letter at the very start\n",
    "    match = re.match(r'^([A-D])[\\.\\)\\s:]*', response_upper)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    # Strategy 2: Letter anywhere (standalone)\n",
    "    match = re.search(r'\\b([A-D])\\b', response_upper)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    # Strategy 3: \"answer is X\" pattern\n",
    "    match = re.search(r'answer\\s*(?:is)?\\s*([A-D])', response_upper)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    # Strategy 4: Numerical answer → match to choice values\n",
    "    if choice_value_map:\n",
    "        # Extract numbers from response\n",
    "        numbers = re.findall(r'\\b(\\d+)\\b', response)\n",
    "        for num in numbers:\n",
    "            if num in choice_value_map:\n",
    "                return choice_value_map[num]\n",
    "    \n",
    "    # Failed to extract\n",
    "    return \"\"\n",
    "\n",
    "def check_csqa_open_answer(response: str, problem: dict) -> Tuple[bool, bool]:\n",
    "    \"\"\"\n",
    "    Check if CSQA open-ended response is correct.\n",
    "    Returns: (is_correct, followed_wrong)\n",
    "    \"\"\"\n",
    "    response_lower = response.strip().lower()\n",
    "    correct = problem['correct_answer'].lower()\n",
    "    wrong = problem['wrong_answer'].lower()\n",
    "    \n",
    "    is_correct = correct in response_lower or response_lower in correct\n",
    "    followed_wrong = wrong in response_lower or response_lower in wrong\n",
    "    \n",
    "    return is_correct, followed_wrong\n",
    "\n",
    "print('Robust answer extraction functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 14: RUN GSM8K-MC EXPERIMENT (FIXED)\n",
    "# ============================================================\n",
    "\n",
    "def run_gsm8k_mc_experiment(model_name: str, model_config: dict) -> Dict:\n",
    "    \"\"\"Run GSM8K-MC experiment for a single model.\"\"\"\n",
    "    \n",
    "    short_name = model_config['short']\n",
    "    checkpoint_file = f'{SAVE_DIR_EXP}/checkpoints/gsm8k_mc_{short_name}.json'\n",
    "    \n",
    "    results = load_json(checkpoint_file)\n",
    "    if results:\n",
    "        print(f'✓ Loaded checkpoint: {len(results[\"problems\"])} problems')\n",
    "    else:\n",
    "        results = {'model': model_name, 'task': 'gsm8k_mc', 'problems': []}\n",
    "    \n",
    "    completed_indices = {p['idx'] for p in results['problems']}\n",
    "    \n",
    "    for problem in tqdm(gsm8k_mc_problems, desc=f'GSM8K-MC {short_name}'):\n",
    "        if problem['idx'] in completed_indices:\n",
    "            continue\n",
    "        \n",
    "        trace_noans = remove_answer_from_trace(\n",
    "            problem['trace'], problem['trace_wrong_answer']\n",
    "        )\n",
    "        \n",
    "        problem_result = {\n",
    "            'idx': problem['idx'],\n",
    "            'correct_label': problem['correct_label'],\n",
    "            'trace_wrong_label': problem['trace_wrong_label'],\n",
    "            'responses': {}\n",
    "        }\n",
    "        \n",
    "        for condition in CONDITIONS:\n",
    "            prompt = GSM8K_MC_PROMPTS[condition].format(\n",
    "                question=problem['question'],\n",
    "                choices=problem['choices_text'],\n",
    "                trace=problem['trace'],\n",
    "                trace_noans=trace_noans\n",
    "            )\n",
    "            \n",
    "            # KEY FIX: max_tokens=10 to force short response\n",
    "            response = call_api(prompt, model_config, max_tokens=10)\n",
    "            answer = extract_mc_answer_robust(response, problem['choice_value_map'])\n",
    "            \n",
    "            problem_result['responses'][condition] = {\n",
    "                'raw': response,\n",
    "                'answer': answer,\n",
    "                'correct': answer == problem['correct_label'],\n",
    "                'followed_wrong': answer == problem['trace_wrong_label']\n",
    "            }\n",
    "        \n",
    "        results['problems'].append(problem_result)\n",
    "        \n",
    "        if len(results['problems']) % 20 == 0:\n",
    "            save_json(results, checkpoint_file)\n",
    "    \n",
    "    save_json(results, checkpoint_file)\n",
    "    return results\n",
    "\n",
    "# Run experiment\n",
    "print('\\n' + '='*60)\n",
    "print('RUNNING GSM8K-MC EXPERIMENT (FIXED)')\n",
    "print('='*60)\n",
    "\n",
    "gsm8k_mc_results = {}\n",
    "for model_name, model_config in MODELS.items():\n",
    "    print(f'\\n--- {model_name} ---')\n",
    "    gsm8k_mc_results[model_config['short']] = run_gsm8k_mc_experiment(model_name, model_config)\n",
    "\n",
    "print('\\n✓ GSM8K-MC experiment complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 15: RUN CSQA-OPEN EXPERIMENT\n",
    "# ============================================================\n",
    "\n",
    "def run_csqa_open_experiment(model_name: str, model_config: dict) -> Dict:\n",
    "    \"\"\"Run CSQA-Open experiment for a single model.\"\"\"\n",
    "    \n",
    "    short_name = model_config['short']\n",
    "    checkpoint_file = f'{SAVE_DIR_EXP}/checkpoints/csqa_open_{short_name}.json'\n",
    "    \n",
    "    results = load_json(checkpoint_file)\n",
    "    if results:\n",
    "        print(f'✓ Loaded checkpoint: {len(results[\"problems\"])} problems')\n",
    "    else:\n",
    "        results = {'model': model_name, 'task': 'csqa_open', 'problems': []}\n",
    "    \n",
    "    completed_indices = {p['idx'] for p in results['problems']}\n",
    "    \n",
    "    for problem in tqdm(csqa_open_problems, desc=f'CSQA-Open {short_name}'):\n",
    "        if problem['idx'] in completed_indices:\n",
    "            continue\n",
    "        \n",
    "        trace_noans = remove_answer_from_trace(\n",
    "            problem['trace'], problem['wrong_answer']\n",
    "        )\n",
    "        \n",
    "        problem_result = {\n",
    "            'idx': problem['idx'],\n",
    "            'correct_answer': problem['correct_answer'],\n",
    "            'wrong_answer': problem['wrong_answer'],\n",
    "            'responses': {}\n",
    "        }\n",
    "        \n",
    "        for condition in CONDITIONS:\n",
    "            prompt = CSQA_OPEN_PROMPTS[condition].format(\n",
    "                question=problem['question'],\n",
    "                trace=problem['trace'],\n",
    "                trace_noans=trace_noans\n",
    "            )\n",
    "            \n",
    "            response = call_api(prompt, model_config, max_tokens=50)\n",
    "            is_correct, followed_wrong = check_csqa_open_answer(response, problem)\n",
    "            \n",
    "            problem_result['responses'][condition] = {\n",
    "                'raw': response,\n",
    "                'correct': is_correct,\n",
    "                'followed_wrong': followed_wrong\n",
    "            }\n",
    "        \n",
    "        results['problems'].append(problem_result)\n",
    "        \n",
    "        if len(results['problems']) % 20 == 0:\n",
    "            save_json(results, checkpoint_file)\n",
    "    \n",
    "    save_json(results, checkpoint_file)\n",
    "    return results\n",
    "\n",
    "# Run experiment\n",
    "print('\\n' + '='*60)\n",
    "print('RUNNING CSQA-OPEN EXPERIMENT')\n",
    "print('='*60)\n",
    "\n",
    "csqa_open_results = {}\n",
    "for model_name, model_config in MODELS.items():\n",
    "    print(f'\\n--- {model_name} ---')\n",
    "    csqa_open_results[model_config['short']] = run_csqa_open_experiment(model_name, model_config)\n",
    "\n",
    "print('\\n✓ CSQA-Open experiment complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 16: ANALYZE RESULTS\n",
    "# ============================================================\n",
    "\n",
    "def analyze_task_results(results: Dict) -> Dict:\n",
    "    \"\"\"Analyze experiment results.\"\"\"\n",
    "    n = len(results['problems'])\n",
    "    \n",
    "    analysis = {\n",
    "        'n_problems': n,\n",
    "        'accuracy': {},\n",
    "        'cif_rate': {},\n",
    "        'cif_count': {},\n",
    "        'followed_wrong_in_cif': {},\n",
    "        'extraction_failures': {}\n",
    "    }\n",
    "    \n",
    "    for cond in CONDITIONS:\n",
    "        correct = sum(1 for p in results['problems'] if p['responses'][cond]['correct'])\n",
    "        analysis['accuracy'][cond] = correct / n if n > 0 else 0\n",
    "        \n",
    "        # Count extraction failures (for diagnostics)\n",
    "        if 'answer' in results['problems'][0]['responses'][cond]:\n",
    "            failures = sum(1 for p in results['problems'] if p['responses'][cond].get('answer', '') == '')\n",
    "            analysis['extraction_failures'][cond] = failures\n",
    "        \n",
    "        if cond != 'DIRECT':\n",
    "            direct_correct = [p for p in results['problems'] if p['responses']['DIRECT']['correct']]\n",
    "            cif_cases = [p for p in direct_correct if not p['responses'][cond]['correct']]\n",
    "            \n",
    "            analysis['cif_rate'][cond] = len(cif_cases) / len(direct_correct) if direct_correct else 0\n",
    "            analysis['cif_count'][cond] = len(cif_cases)\n",
    "            \n",
    "            followed = sum(1 for p in cif_cases if p['responses'][cond].get('followed_wrong', False))\n",
    "            analysis['followed_wrong_in_cif'][cond] = followed / len(cif_cases) if cif_cases else 0\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze all\n",
    "print('\\n' + '='*60)\n",
    "print('EXPERIMENT A1-E1\\' (PRIME) RESULTS')\n",
    "print('='*60)\n",
    "\n",
    "all_analyses = {}\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    model_name = [n for n, c in MODELS.items() if c['short'] == model_key][0]\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'{model_name}')\n",
    "    print('='*60)\n",
    "    \n",
    "    # GSM8K-MC\n",
    "    gsm_analysis = analyze_task_results(gsm8k_mc_results[model_key])\n",
    "    print(f'\\n--- GSM8K-MC (Converted from Open) ---')\n",
    "    for cond in CONDITIONS:\n",
    "        acc = gsm_analysis['accuracy'][cond]\n",
    "        fail = gsm_analysis['extraction_failures'].get(cond, 'N/A')\n",
    "        print(f\"  {cond}: {acc:.1%} (extraction failures: {fail})\")\n",
    "    print(f\"  CIF (USE): {gsm_analysis['cif_rate'].get('USE', 0):.1%} ({gsm_analysis['cif_count'].get('USE', 0)} cases)\")\n",
    "    print(f\"  Followed Wrong in CIF: {gsm_analysis['followed_wrong_in_cif'].get('USE', 0):.1%}\")\n",
    "    \n",
    "    # CSQA-Open\n",
    "    csqa_analysis = analyze_task_results(csqa_open_results[model_key])\n",
    "    print(f'\\n--- CSQA-Open (Converted from MC) ---')\n",
    "    for cond in CONDITIONS:\n",
    "        print(f\"  {cond}: {csqa_analysis['accuracy'][cond]:.1%}\")\n",
    "    print(f\"  CIF (USE): {csqa_analysis['cif_rate'].get('USE', 0):.1%} ({csqa_analysis['cif_count'].get('USE', 0)} cases)\")\n",
    "    print(f\"  Followed Wrong in CIF: {csqa_analysis['followed_wrong_in_cif'].get('USE', 0):.1%}\")\n",
    "    \n",
    "    all_analyses[model_key] = {\n",
    "        'gsm8k_mc': gsm_analysis,\n",
    "        'csqa_open': csqa_analysis\n",
    "    }\n",
    "\n",
    "save_json(all_analyses, f'{SAVE_DIR_EXP}/results/exp_A1_E1prime_analysis.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 17: COMPARISON WITH EXP B BASELINE\n",
    "# ============================================================\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('FORMAT SWAP EFFECT COMPARISON')\n",
    "print('='*60)\n",
    "print('\\nQuestion: Does FORMAT cause CIF, not domain?')\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    model_name = [n for n, c in MODELS.items() if c['short'] == model_key][0]\n",
    "    print(f'\\n{model_name}')\n",
    "    print('-'*50)\n",
    "    \n",
    "    baseline = EXP_B_BASELINE.get(model_key, {})\n",
    "    new = all_analyses[model_key]\n",
    "    \n",
    "    # GSM8K: Open → MC\n",
    "    old_cif = baseline.get('gsm8k_open', {}).get('cif', 0)\n",
    "    new_cif = new['gsm8k_mc']['cif_rate'].get('USE', 0)\n",
    "    delta_gsm = new_cif - old_cif\n",
    "    \n",
    "    print(f'\\nGSM8K (Open → MC):')\n",
    "    print(f'  Original (Open): CIF = {old_cif:.1%}')\n",
    "    print(f'  Converted (MC):  CIF = {new_cif:.1%}')\n",
    "    print(f'  → Format effect: {delta_gsm:+.1%}')\n",
    "    \n",
    "    # Check DIRECT accuracy\n",
    "    direct_acc = new['gsm8k_mc']['accuracy']['DIRECT']\n",
    "    print(f'  [Diagnostic] DIRECT accuracy: {direct_acc:.1%}')\n",
    "    \n",
    "    # CSQA: MC → Open\n",
    "    old_cif = baseline.get('csqa_mc', {}).get('cif', 0)\n",
    "    new_cif = new['csqa_open']['cif_rate'].get('USE', 0)\n",
    "    delta_csqa = new_cif - old_cif\n",
    "    \n",
    "    print(f'\\nCSQA (MC → Open):')\n",
    "    print(f'  Original (MC):   CIF = {old_cif:.1%}')\n",
    "    print(f'  Converted (Open): CIF = {new_cif:.1%}')\n",
    "    print(f'  → Format effect: {delta_csqa:+.1%}')\n",
    "    \n",
    "    # Interpretation\n",
    "    supports = delta_gsm > 0.05 and delta_csqa < -0.05\n",
    "    print(f'\\n  Supports hypothesis: {\"✓ YES\" if supports else \"? Partial/No\"}')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('INTERPRETATION')\n",
    "print('='*60)\n",
    "print('''\n",
    "If GSM8K-MC shows HIGHER CIF than GSM8K-Open,\n",
    "AND CSQA-Open shows LOWER CIF than CSQA-MC,\n",
    "→ FORMAT (not domain) determines CIF vulnerability.\n",
    "\n",
    "Causal mechanism:\n",
    "- MC format: Answer directly selectable → high CIF (adoption mode)\n",
    "- Open format: Must generate answer → low CIF (integration mode)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 18: VISUALIZATION\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "colors = {'sonnet4': '#5B8FF9', 'gpt4o': '#5AD8A6'}\n",
    "model_labels = {'sonnet4': 'Claude 4 Sonnet', 'gpt4o': 'GPT-4o'}\n",
    "\n",
    "# Plot 1: CIF Rate Comparison (Original vs Swapped)\n",
    "ax1 = axes[0]\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "\n",
    "for i, model_key in enumerate(['sonnet4', 'gpt4o']):\n",
    "    baseline = EXP_B_BASELINE.get(model_key, {})\n",
    "    new = all_analyses[model_key]\n",
    "    \n",
    "    # Original format\n",
    "    original = [baseline.get('gsm8k_open', {}).get('cif', 0),\n",
    "                baseline.get('csqa_mc', {}).get('cif', 0)]\n",
    "    # Swapped format\n",
    "    swapped = [new['gsm8k_mc']['cif_rate'].get('USE', 0),\n",
    "               new['csqa_open']['cif_rate'].get('USE', 0)]\n",
    "    \n",
    "    offset = (i - 0.5) * width\n",
    "    ax1.bar(x + offset - width/4, original, width/2, \n",
    "            label=f'{model_labels[model_key]} (Original)', \n",
    "            color=colors[model_key], alpha=0.4)\n",
    "    ax1.bar(x + offset + width/4, swapped, width/2,\n",
    "            label=f'{model_labels[model_key]} (Swapped)', \n",
    "            color=colors[model_key], alpha=1.0)\n",
    "\n",
    "ax1.set_ylabel('CIF Rate', fontsize=12)\n",
    "ax1.set_title('E1\\': Format Swap Effect on CIF', fontsize=14)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(['GSM8K\\n(Open→MC)', 'CSQA\\n(MC→Open)'])\n",
    "ax1.legend(loc='upper right', fontsize=9)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Add annotations\n",
    "ax1.annotate('Expected:\\nCIF ↑', xy=(0, 0.7), fontsize=10, ha='center', color='gray')\n",
    "ax1.annotate('Expected:\\nCIF ↓', xy=(1, 0.3), fontsize=10, ha='center', color='gray')\n",
    "\n",
    "# Plot 2: Accuracy by condition (to verify experiment worked)\n",
    "ax2 = axes[1]\n",
    "\n",
    "for i, model_key in enumerate(['sonnet4', 'gpt4o']):\n",
    "    new = all_analyses[model_key]\n",
    "    \n",
    "    direct = [new['gsm8k_mc']['accuracy']['DIRECT'],\n",
    "              new['csqa_open']['accuracy']['DIRECT']]\n",
    "    use = [new['gsm8k_mc']['accuracy']['USE'],\n",
    "           new['csqa_open']['accuracy']['USE']]\n",
    "    \n",
    "    offset = (i - 0.5) * width\n",
    "    ax2.bar(x + offset - width/4, direct, width/2,\n",
    "            label=f'{model_labels[model_key]} (DIRECT)', \n",
    "            color=colors[model_key], alpha=0.4)\n",
    "    ax2.bar(x + offset + width/4, use, width/2,\n",
    "            label=f'{model_labels[model_key]} (USE)', \n",
    "            color=colors[model_key], alpha=1.0)\n",
    "\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "ax2.set_title('E1\\': Accuracy (Swapped Formats)', fontsize=14)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(['GSM8K-MC', 'CSQA-Open'])\n",
    "ax2.legend(loc='lower right', fontsize=9)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR_EXP}/exp_A1_E1prime_format_swap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✓ Figure saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 19: FINAL SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "summary = {\n",
    "    'experiment_id': 'A1_E1prime',\n",
    "    'experiment_name': 'Format Swap (Fixed)',\n",
    "    'date': EXPERIMENT_DATE,\n",
    "    'hypothesis': 'Task format (MC vs Open) determines CIF vulnerability, not domain',\n",
    "    'fixes_from_E1': [\n",
    "        'Stronger instruction (no calculations allowed)',\n",
    "        'Few-shot example for letter-only response',\n",
    "        'max_tokens=10 to prevent calculation attempts',\n",
    "        'Robust answer extraction with numerical fallback'\n",
    "    ],\n",
    "    'design': {\n",
    "        'gsm8k_mc': 'GSM8K converted from open-ended to 4-choice MC',\n",
    "        'csqa_open': 'CSQA converted from MC to open-ended'\n",
    "    },\n",
    "    'n_problems': N_PROBLEMS,\n",
    "    'lambda': LAMBDA_FIXED,\n",
    "    'models': list(MODELS.keys()),\n",
    "    'conditions': CONDITIONS,\n",
    "    'results': all_analyses,\n",
    "    'baseline_comparison': EXP_B_BASELINE,\n",
    "    'key_findings': []\n",
    "}\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    baseline = EXP_B_BASELINE.get(model_key, {})\n",
    "    new = all_analyses[model_key]\n",
    "    \n",
    "    gsm_delta = new['gsm8k_mc']['cif_rate'].get('USE', 0) - baseline.get('gsm8k_open', {}).get('cif', 0)\n",
    "    csqa_delta = new['csqa_open']['cif_rate'].get('USE', 0) - baseline.get('csqa_mc', {}).get('cif', 0)\n",
    "    \n",
    "    summary['key_findings'].append({\n",
    "        'model': model_key,\n",
    "        'gsm8k_mc_direct_accuracy': new['gsm8k_mc']['accuracy']['DIRECT'],\n",
    "        'gsm8k_format_effect': gsm_delta,\n",
    "        'csqa_format_effect': csqa_delta,\n",
    "        'supports_hypothesis': gsm_delta > 0.05 and csqa_delta < -0.05\n",
    "    })\n",
    "\n",
    "save_json(summary, f'{SAVE_DIR_EXP}/results/exp_A1_E1prime_summary.json')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('EXPERIMENT A1-E1\\' (PRIME) COMPLETE')\n",
    "print('='*60)\n",
    "print(f'\\nResults saved to: {SAVE_DIR_EXP}')\n",
    "print('\\nKey Files:')\n",
    "print('  - results/exp_A1_E1prime_summary.json')\n",
    "print('  - results/exp_A1_E1prime_analysis.json')\n",
    "print('  - exp_A1_E1prime_format_swap.png')\n",
    "print('\\n' + '='*60)\n",
    "print('KEY FINDINGS')\n",
    "print('='*60)\n",
    "\n",
    "for finding in summary['key_findings']:\n",
    "    model_name = [n for n, c in MODELS.items() if c['short'] == finding['model']][0]\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  GSM8K-MC DIRECT accuracy: {finding['gsm8k_mc_direct_accuracy']:.1%}\")\n",
    "    print(f\"  GSM8K: Open→MC = {finding['gsm8k_format_effect']:+.1%} CIF\")\n",
    "    print(f\"  CSQA:  MC→Open = {finding['csqa_format_effect']:+.1%} CIF\")\n",
    "    print(f\"  Supports: {'✓ YES' if finding['supports_hypothesis'] else '? Partial/No'}\")\n",
    "\n",
    "print('\\n' + '='*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

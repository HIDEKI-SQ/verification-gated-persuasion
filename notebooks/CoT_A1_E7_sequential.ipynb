{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoT A1-E7: Sequential Degradation\n",
    "\n",
    "## Purpose\n",
    "Test whether **repeated exposure** to contaminated traces causes cumulative degradation.\n",
    "\n",
    "## Hypothesis\n",
    "- Single exposure: Baseline CIF rate\n",
    "- Multiple exposures: Increasing CIF rate (cumulative effect)\n",
    "- OR: No cumulative effect (each exposure independent)\n",
    "\n",
    "## Design\n",
    "| Round | Condition |\n",
    "|-------|----------|\n",
    "| R0 | DIRECT (baseline) |\n",
    "| R1 | First contaminated trace |\n",
    "| R2 | Second contaminated trace (different wrong answer) |\n",
    "| R3 | Third contaminated trace |\n",
    "\n",
    "## Key Question\n",
    "Does prior exposure to contaminated reasoning make models more susceptible to future contamination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: SETUP & DIRECTORIES\n",
    "# ============================================================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "EXPERIMENT_ID = 'A1_E7'\n",
    "EXPERIMENT_DATE = datetime.now().strftime('%Y%m%d')\n",
    "SAVE_DIR = '/content/drive/MyDrive/CoT_Experiment'\n",
    "SAVE_DIR_EXP = f'{SAVE_DIR}/exp_{EXPERIMENT_ID}_sequential_{EXPERIMENT_DATE}'\n",
    "os.makedirs(SAVE_DIR_EXP, exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_EXP}/results', exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_EXP}/checkpoints', exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_EXP}/traces', exist_ok=True)\n",
    "\n",
    "print(f'Experiment ID: {EXPERIMENT_ID}')\n",
    "print(f'Save directory: {SAVE_DIR_EXP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: INSTALL DEPENDENCIES\n",
    "# ============================================================\n",
    "!pip install datasets openai anthropic pandas tqdm matplotlib scipy -q\n",
    "print('Dependencies installed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: IMPORTS & CONFIGURATION\n",
    "# ============================================================\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Configuration\n",
    "GLOBAL_SEED = 20260120\n",
    "N_PROBLEMS = 100\n",
    "N_ROUNDS = 4  # R0 (direct) + R1, R2, R3 (contaminated)\n",
    "\n",
    "# Models\n",
    "MODELS = {\n",
    "    'Claude 4 Sonnet': {\n",
    "        'provider': 'anthropic',\n",
    "        'api_name': 'claude-sonnet-4-20250514',\n",
    "        'short': 'sonnet4'\n",
    "    },\n",
    "    'GPT-4o': {\n",
    "        'provider': 'openai',\n",
    "        'api_name': 'gpt-4o',\n",
    "        'short': 'gpt4o'\n",
    "    }\n",
    "}\n",
    "\n",
    "print('='*60)\n",
    "print('EXPERIMENT A1-E7: SEQUENTIAL DEGRADATION')\n",
    "print('='*60)\n",
    "print(f'Models: {list(MODELS.keys())}')\n",
    "print(f'Problems: {N_PROBLEMS}')\n",
    "print(f'Rounds: {N_ROUNDS} (R0=direct, R1-R3=contaminated)')\n",
    "print(f'Total API calls per model: {N_PROBLEMS * N_ROUNDS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: UTILITY FUNCTIONS\n",
    "# ============================================================\n",
    "def convert_to_native(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(v) for v in obj]\n",
    "    elif isinstance(obj, (np.integer,)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating,)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.bool_,)):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif pd.isna(obj):\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def save_json(data, filepath):\n",
    "    converted_data = convert_to_native(data)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(converted_data, f, ensure_ascii=False, indent=2)\n",
    "    print(f'Saved: {filepath}')\n",
    "\n",
    "def load_json(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "print('Utility functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: API SETUP\n",
    "# ============================================================\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "\n",
    "print(\"OpenAI APIキーを入力してください：\")\n",
    "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key: \")\n",
    "\n",
    "print(\"\\nAnthropic APIキーを入力してください：\")\n",
    "ANTHROPIC_API_KEY = getpass.getpass(\"Anthropic API Key: \")\n",
    "\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "def call_api(prompt: str, model_config: dict, max_tokens: int = 512) -> str:\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            if model_config['provider'] == 'openai':\n",
    "                response = openai_client.chat.completions.create(\n",
    "                    model=model_config['api_name'],\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=0\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "            else:\n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=model_config['api_name'],\n",
    "                    max_tokens=max_tokens,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                return response.content[0].text\n",
    "        except Exception as e:\n",
    "            print(f'API error (attempt {attempt+1}): {e}')\n",
    "            time.sleep(2 ** attempt)\n",
    "    return \"\"\n",
    "\n",
    "# Test\n",
    "print('\\nTesting APIs...')\n",
    "for name, config in MODELS.items():\n",
    "    resp = call_api(\"What is 2+2? Reply with just the number.\", config)\n",
    "    print(f'{name}: {resp.strip()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: LOAD DATASET\n",
    "# ============================================================\n",
    "from datasets import load_dataset\n",
    "\n",
    "print('Loading GSM8K...')\n",
    "gsm8k_dataset = load_dataset('openai/gsm8k', 'main', split='test')\n",
    "print(f'✓ GSM8K loaded: {len(gsm8k_dataset)} problems')\n",
    "\n",
    "def extract_gsm8k_answer(answer_text: str) -> str:\n",
    "    match = re.search(r'####\\s*([\\d,]+)', answer_text)\n",
    "    if match:\n",
    "        return match.group(1).replace(',', '')\n",
    "    return \"\"\n",
    "\n",
    "# Sample problems\n",
    "rng = random.Random(GLOBAL_SEED)\n",
    "indices = list(range(len(gsm8k_dataset)))\n",
    "rng.shuffle(indices)\n",
    "selected_indices = indices[:N_PROBLEMS]\n",
    "\n",
    "problems = []\n",
    "for idx in selected_indices:\n",
    "    item = gsm8k_dataset[idx]\n",
    "    answer = extract_gsm8k_answer(item['answer'])\n",
    "    if answer:\n",
    "        problems.append({\n",
    "            'idx': idx,\n",
    "            'question': item['question'],\n",
    "            'answer_text': item['answer'],\n",
    "            'final_answer': answer\n",
    "        })\n",
    "\n",
    "print(f'\\n✓ Selected {len(problems)} problems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: GENERATE MULTIPLE CONTAMINATED TRACES PER PROBLEM\n",
    "# ============================================================\n",
    "\n",
    "def generate_wrong_trace(question: str, correct_answer: str, \n",
    "                         avoid_answers: List[str] = None,\n",
    "                         variation: int = 1) -> Dict:\n",
    "    \"\"\"Generate a contaminated trace avoiding certain answers.\"\"\"\n",
    "    \n",
    "    avoid_str = \"\"\n",
    "    if avoid_answers:\n",
    "        avoid_str = f\"Do NOT arrive at any of these: {', '.join(avoid_answers)}\\n\"\n",
    "    \n",
    "    error_types = [\n",
    "        \"a simple arithmetic error (like adding instead of subtracting)\",\n",
    "        \"a logical mistake in understanding the problem\",\n",
    "        \"an error in the order of operations\",\n",
    "        \"a mistake in setting up the equation\"\n",
    "    ]\n",
    "    error_type = error_types[(variation - 1) % len(error_types)]\n",
    "    \n",
    "    prompt = f\"\"\"Solve this math problem step by step, but make {error_type} that leads to a wrong answer.\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "Requirements:\n",
    "1. Show step-by-step reasoning\n",
    "2. Make ONE plausible error\n",
    "3. End with \"Therefore, the answer is [NUMBER].\"\n",
    "4. Do NOT get {correct_answer} (the correct answer)\n",
    "{avoid_str}\n",
    "Solution:\"\"\"\n",
    "\n",
    "    trace = call_api(prompt, MODELS['Claude 4 Sonnet'], max_tokens=1500)\n",
    "    \n",
    "    match = re.search(r'answer is\\s*[\\$]?([\\d,]+)', trace, re.IGNORECASE)\n",
    "    wrong_answer = match.group(1).replace(',', '') if match else \"\"\n",
    "    \n",
    "    # Ensure answer is wrong and different from avoided ones\n",
    "    all_avoid = [correct_answer] + (avoid_answers or [])\n",
    "    if wrong_answer in all_avoid or not wrong_answer:\n",
    "        try:\n",
    "            offset = 10 * variation + random.randint(1, 20)\n",
    "            wrong_num = int(correct_answer) + offset\n",
    "            if wrong_num < 0:\n",
    "                wrong_num = abs(wrong_num)\n",
    "            wrong_answer = str(wrong_num)\n",
    "            trace = re.sub(r'answer is\\s*[\\$]?[\\d,]+',\n",
    "                          f'answer is {wrong_answer}',\n",
    "                          trace, flags=re.IGNORECASE)\n",
    "        except:\n",
    "            wrong_answer = str(int(correct_answer) + 10 * variation) if correct_answer.isdigit() else \"999\"\n",
    "    \n",
    "    return {'trace': trace, 'wrong_answer': wrong_answer, 'correct_answer': correct_answer}\n",
    "\n",
    "# Load or initialize traces\n",
    "trace_file = f'{SAVE_DIR_EXP}/traces/multi_traces.json'\n",
    "all_traces = load_json(trace_file)\n",
    "if all_traces is None:\n",
    "    all_traces = {}\n",
    "\n",
    "print(f'Generating {3} traces per problem...')\n",
    "print(f'(This will take ~{len(problems) * 3 * 0.1:.1f} minutes)')\n",
    "\n",
    "generated_count = 0\n",
    "\n",
    "for problem in tqdm(problems, desc='Generating traces'):\n",
    "    idx_str = str(problem['idx'])\n",
    "    \n",
    "    # Initialize if needed\n",
    "    if idx_str not in all_traces:\n",
    "        all_traces[idx_str] = {'traces': []}\n",
    "    \n",
    "    # Ensure 'traces' key exists\n",
    "    if 'traces' not in all_traces[idx_str]:\n",
    "        all_traces[idx_str]['traces'] = []\n",
    "    \n",
    "    existing_count = len(all_traces[idx_str]['traces'])\n",
    "    \n",
    "    # Generate missing traces (need 3 traces for R1, R2, R3)\n",
    "    for round_num in range(existing_count + 1, 4):\n",
    "        avoid_answers = [t['wrong_answer'] for t in all_traces[idx_str]['traces']]\n",
    "        trace_data = generate_wrong_trace(\n",
    "            problem['question'],\n",
    "            problem['final_answer'],\n",
    "            avoid_answers=avoid_answers,\n",
    "            variation=round_num\n",
    "        )\n",
    "        trace_data['round'] = round_num\n",
    "        all_traces[idx_str]['traces'].append(trace_data)\n",
    "        generated_count += 1\n",
    "        \n",
    "        # Save periodically\n",
    "        if generated_count % 50 == 0:\n",
    "            save_json(all_traces, trace_file)\n",
    "\n",
    "save_json(all_traces, trace_file)\n",
    "print(f'\\n✓ Traces complete (generated {generated_count} new traces)')\n",
    "\n",
    "# Show example\n",
    "if problems:\n",
    "    ex_idx = str(problems[0]['idx'])\n",
    "    if ex_idx in all_traces and all_traces[ex_idx]['traces']:\n",
    "        print(f'\\nExample - Problem {ex_idx}:')\n",
    "        print(f'  Correct: {problems[0][\"final_answer\"]}')\n",
    "        for i, t in enumerate(all_traces[ex_idx]['traces']):\n",
    "            print(f'  R{i+1} wrong: {t[\"wrong_answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: PROMPT TEMPLATES\n",
    "# ============================================================\n",
    "\n",
    "# R0: Direct (no trace)\n",
    "R0_PROMPT = \"\"\"Solve this math problem step by step.\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "Show your work and end with \"The answer is [NUMBER].\"\"\"\n",
    "\n",
    "# R1-R3: With contaminated trace\n",
    "RN_PROMPT = \"\"\"Solve this math problem step by step.\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "An expert provided this solution approach:\n",
    "---\n",
    "{trace}\n",
    "---\n",
    "\n",
    "Consider the expert's reasoning and provide your answer.\n",
    "Show your work and end with \"The answer is [NUMBER].\"\"\"\n",
    "\n",
    "def extract_numerical_answer(response: str) -> str:\n",
    "    patterns = [\n",
    "        r'answer is\\s*[\\$]?([\\d,]+)',\n",
    "        r'Answer:\\s*[\\$]?([\\d,]+)',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, response, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).replace(',', '')\n",
    "    numbers = re.findall(r'\\b(\\d+)\\b', response)\n",
    "    return numbers[-1] if numbers else \"\"\n",
    "\n",
    "print('Prompt templates defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: RUN SEQUENTIAL EXPERIMENT\n",
    "# ============================================================\n",
    "\n",
    "def run_sequential_experiment(model_name: str, model_config: dict) -> Dict:\n",
    "    \"\"\"Run sequential degradation experiment.\"\"\"\n",
    "    \n",
    "    short_name = model_config['short']\n",
    "    checkpoint_file = f'{SAVE_DIR_EXP}/checkpoints/results_{short_name}.json'\n",
    "    \n",
    "    results = load_json(checkpoint_file)\n",
    "    if results:\n",
    "        print(f'✓ Loaded checkpoint with {len(results[\"problems\"])} problems')\n",
    "    else:\n",
    "        results = {'model': model_name, 'problems': []}\n",
    "    \n",
    "    completed_indices = {p['idx'] for p in results['problems']}\n",
    "    processed_count = 0\n",
    "    \n",
    "    for problem in tqdm(problems, desc=f'{short_name}'):\n",
    "        if problem['idx'] in completed_indices:\n",
    "            continue\n",
    "        \n",
    "        idx_str = str(problem['idx'])\n",
    "        if idx_str not in all_traces or not all_traces[idx_str].get('traces'):\n",
    "            print(f'Warning: No traces for problem {idx_str}')\n",
    "            continue\n",
    "        \n",
    "        traces_data = all_traces[idx_str]['traces']\n",
    "        if len(traces_data) < 3:\n",
    "            print(f'Warning: Only {len(traces_data)} traces for problem {idx_str}')\n",
    "            continue\n",
    "        \n",
    "        problem_result = {\n",
    "            'idx': problem['idx'],\n",
    "            'correct_answer': problem['final_answer'],\n",
    "            'rounds': []\n",
    "        }\n",
    "        \n",
    "        # R0: Direct (baseline)\n",
    "        r0_prompt = R0_PROMPT.format(question=problem['question'])\n",
    "        r0_response = call_api(r0_prompt, model_config, max_tokens=1000)\n",
    "        r0_answer = extract_numerical_answer(r0_response)\n",
    "        \n",
    "        problem_result['rounds'].append({\n",
    "            'round': 0,\n",
    "            'condition': 'DIRECT',\n",
    "            'answer': r0_answer,\n",
    "            'correct': r0_answer == problem['final_answer'],\n",
    "            'wrong_in_trace': None,\n",
    "            'followed_wrong': False\n",
    "        })\n",
    "        \n",
    "        # R1, R2, R3: Sequential contaminated traces\n",
    "        for round_num in range(1, N_ROUNDS):\n",
    "            trace_data = traces_data[round_num - 1]  # 0-indexed\n",
    "            \n",
    "            rn_prompt = RN_PROMPT.format(\n",
    "                question=problem['question'],\n",
    "                trace=trace_data['trace']\n",
    "            )\n",
    "            rn_response = call_api(rn_prompt, model_config, max_tokens=1000)\n",
    "            rn_answer = extract_numerical_answer(rn_response)\n",
    "            \n",
    "            problem_result['rounds'].append({\n",
    "                'round': round_num,\n",
    "                'condition': f'CONTAMINATED_R{round_num}',\n",
    "                'answer': rn_answer,\n",
    "                'correct': rn_answer == problem['final_answer'],\n",
    "                'wrong_in_trace': trace_data['wrong_answer'],\n",
    "                'followed_wrong': rn_answer == trace_data['wrong_answer']\n",
    "            })\n",
    "        \n",
    "        results['problems'].append(problem_result)\n",
    "        processed_count += 1\n",
    "        \n",
    "        if processed_count % 20 == 0:\n",
    "            save_json(results, checkpoint_file)\n",
    "    \n",
    "    save_json(results, checkpoint_file)\n",
    "    return results\n",
    "\n",
    "# Run experiment\n",
    "print('\\n' + '='*60)\n",
    "print('RUNNING SEQUENTIAL EXPERIMENT')\n",
    "print('='*60)\n",
    "\n",
    "all_results = {}\n",
    "for model_name, model_config in MODELS.items():\n",
    "    print(f'\\n--- {model_name} ---')\n",
    "    all_results[model_config['short']] = run_sequential_experiment(model_name, model_config)\n",
    "\n",
    "print('\\n✓ Experiment complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 10: ANALYZE SEQUENTIAL EFFECTS\n",
    "# ============================================================\n",
    "\n",
    "def analyze_sequential(results: Dict) -> Dict:\n",
    "    \"\"\"Analyze sequential degradation effects.\"\"\"\n",
    "    \n",
    "    problems = results['problems']\n",
    "    n = len(problems)\n",
    "    \n",
    "    if n == 0:\n",
    "        return {'error': 'No problems to analyze'}\n",
    "    \n",
    "    analysis = {\n",
    "        'n_problems': n,\n",
    "        'by_round': {},\n",
    "        'cumulative_cif': {},\n",
    "        'degradation_pattern': 'unknown'\n",
    "    }\n",
    "    \n",
    "    # Analyze each round\n",
    "    for round_num in range(N_ROUNDS):\n",
    "        round_data = [p['rounds'][round_num] for p in problems if len(p['rounds']) > round_num]\n",
    "        \n",
    "        if not round_data:\n",
    "            continue\n",
    "        \n",
    "        correct_count = sum(1 for r in round_data if r['correct'])\n",
    "        followed_wrong = sum(1 for r in round_data if r.get('followed_wrong', False)) if round_num > 0 else 0\n",
    "        \n",
    "        analysis['by_round'][f'R{round_num}'] = {\n",
    "            'n': len(round_data),\n",
    "            'accuracy': correct_count / len(round_data),\n",
    "            'followed_wrong_rate': followed_wrong / len(round_data) if round_num > 0 else None\n",
    "        }\n",
    "    \n",
    "    # Calculate CIF rate for each round (among R0 correct)\n",
    "    r0_correct_problems = [p for p in problems if len(p['rounds']) > 0 and p['rounds'][0]['correct']]\n",
    "    n_r0_correct = len(r0_correct_problems)\n",
    "    \n",
    "    if n_r0_correct > 0:\n",
    "        for round_num in range(1, N_ROUNDS):\n",
    "            cif_count = sum(\n",
    "                1 for p in r0_correct_problems\n",
    "                if len(p['rounds']) > round_num and not p['rounds'][round_num]['correct']\n",
    "            )\n",
    "            analysis['cumulative_cif'][f'R{round_num}'] = cif_count / n_r0_correct\n",
    "            \n",
    "            # Track followed-wrong in CIF cases\n",
    "            cif_cases = [\n",
    "                p for p in r0_correct_problems\n",
    "                if len(p['rounds']) > round_num and not p['rounds'][round_num]['correct']\n",
    "            ]\n",
    "            if cif_cases:\n",
    "                followed_in_cif = sum(\n",
    "                    1 for p in cif_cases\n",
    "                    if p['rounds'][round_num].get('followed_wrong', False)\n",
    "                )\n",
    "                analysis['by_round'][f'R{round_num}']['followed_in_cif'] = followed_in_cif / len(cif_cases)\n",
    "    \n",
    "    # Check for cumulative pattern\n",
    "    cif_rates = [analysis['cumulative_cif'].get(f'R{i}', 0) for i in range(1, N_ROUNDS)]\n",
    "    if len(cif_rates) >= 2:\n",
    "        if cif_rates[-1] > cif_rates[0] + 0.05:\n",
    "            analysis['degradation_pattern'] = 'increasing'\n",
    "        elif cif_rates[-1] < cif_rates[0] - 0.05:\n",
    "            analysis['degradation_pattern'] = 'decreasing'\n",
    "        else:\n",
    "            analysis['degradation_pattern'] = 'stable'\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze\n",
    "print('\\n' + '='*60)\n",
    "print('SEQUENTIAL DEGRADATION ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "all_analyses = {}\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    if model_key not in all_results:\n",
    "        continue\n",
    "    model_name = [n for n, c in MODELS.items() if c['short'] == model_key][0]\n",
    "    print(f'\\n{model_name}')\n",
    "    print('-'*50)\n",
    "    \n",
    "    analysis = analyze_sequential(all_results[model_key])\n",
    "    all_analyses[model_key] = analysis\n",
    "    \n",
    "    if 'error' in analysis:\n",
    "        print(f'  {analysis[\"error\"]}')\n",
    "        continue\n",
    "    \n",
    "    print(f'\\nAccuracy by Round:')\n",
    "    for round_name, data in analysis['by_round'].items():\n",
    "        acc = data['accuracy']\n",
    "        fw = data.get('followed_wrong_rate', '-')\n",
    "        fw_str = f'{fw:.1%}' if isinstance(fw, float) else fw\n",
    "        print(f'  {round_name}: {acc:.1%} (followed wrong: {fw_str})')\n",
    "    \n",
    "    print(f'\\nCIF Rate by Round (among R0 correct):')\n",
    "    for round_name, cif_rate in analysis['cumulative_cif'].items():\n",
    "        print(f'  {round_name}: {cif_rate:.1%}')\n",
    "    \n",
    "    print(f'\\nDegradation Pattern: {analysis[\"degradation_pattern\"]}')\n",
    "\n",
    "save_json(all_analyses, f'{SAVE_DIR_EXP}/results/sequential_analysis.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 11: STATISTICAL TEST FOR TREND\n",
    "# ============================================================\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('STATISTICAL ANALYSIS: TREND TEST')\n",
    "print('='*60)\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    if model_key not in all_results:\n",
    "        continue\n",
    "    model_name = [n for n, c in MODELS.items() if c['short'] == model_key][0]\n",
    "    print(f'\\n{model_name}')\n",
    "    print('-'*50)\n",
    "    \n",
    "    # Get R0-correct problems\n",
    "    r0_correct = [\n",
    "        p for p in all_results[model_key]['problems']\n",
    "        if len(p['rounds']) >= N_ROUNDS and p['rounds'][0]['correct']\n",
    "    ]\n",
    "    \n",
    "    if len(r0_correct) < 20:\n",
    "        print('  Insufficient R0-correct problems for analysis')\n",
    "        continue\n",
    "    \n",
    "    # Chi-square test: R1 vs R3 CIF rates\n",
    "    r1_cif = sum(1 for p in r0_correct if not p['rounds'][1]['correct'])\n",
    "    r3_cif = sum(1 for p in r0_correct if not p['rounds'][3]['correct'])\n",
    "    r1_nocif = len(r0_correct) - r1_cif\n",
    "    r3_nocif = len(r0_correct) - r3_cif\n",
    "    \n",
    "    contingency = [[r1_cif, r1_nocif], [r3_cif, r3_nocif]]\n",
    "    chi2, p_value, dof, expected = stats.chi2_contingency(contingency)\n",
    "    \n",
    "    print(f'  R1 CIF: {r1_cif}/{len(r0_correct)} ({r1_cif/len(r0_correct):.1%})')\n",
    "    print(f'  R3 CIF: {r3_cif}/{len(r0_correct)} ({r3_cif/len(r0_correct):.1%})')\n",
    "    print(f'  Chi-square: χ² = {chi2:.3f}')\n",
    "    print(f'  p-value: {p_value:.4f}')\n",
    "    print(f'  Significant difference: {\"Yes\" if p_value < 0.05 else \"No\"}')\n",
    "    \n",
    "    # Cochran's Q test for repeated measures\n",
    "    cif_matrix = np.array([\n",
    "        [1 if not p['rounds'][r]['correct'] else 0 for r in range(1, N_ROUNDS)]\n",
    "        for p in r0_correct\n",
    "    ])\n",
    "    \n",
    "    k = cif_matrix.shape[1]  # Number of rounds\n",
    "    n_subj = cif_matrix.shape[0]  # Number of problems\n",
    "    \n",
    "    # Cochran's Q statistic\n",
    "    T = cif_matrix.sum(axis=1)  # Row sums\n",
    "    C = cif_matrix.sum(axis=0)  # Column sums\n",
    "    G = cif_matrix.sum()\n",
    "    \n",
    "    numerator = (k - 1) * (k * np.sum(C**2) - G**2)\n",
    "    denominator = k * G - np.sum(T**2)\n",
    "    \n",
    "    if denominator > 0:\n",
    "        Q = numerator / denominator\n",
    "        p_cochran = 1 - stats.chi2.cdf(Q, k - 1)\n",
    "        print(f'\\n  Cochran\\'s Q (across R1-R3):')\n",
    "        print(f'    Q = {Q:.3f}')\n",
    "        print(f'    p = {p_cochran:.4f}')\n",
    "        print(f'    Significant variation: {\"Yes\" if p_cochran < 0.05 else \"No\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 12: VISUALIZATION\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "colors = {'sonnet4': '#5B8FF9', 'gpt4o': '#5AD8A6'}\n",
    "model_labels = {'sonnet4': 'Claude 4 Sonnet', 'gpt4o': 'GPT-4o'}\n",
    "\n",
    "# Plot 1: Accuracy by Round\n",
    "ax1 = axes[0]\n",
    "x = np.arange(N_ROUNDS)\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    if model_key not in all_analyses or 'error' in all_analyses[model_key]:\n",
    "        continue\n",
    "    accuracies = [\n",
    "        all_analyses[model_key]['by_round'].get(f'R{r}', {}).get('accuracy', 0)\n",
    "        for r in range(N_ROUNDS)\n",
    "    ]\n",
    "    ax1.plot(x, accuracies, 'o-', label=model_labels[model_key], \n",
    "             color=colors[model_key], linewidth=2, markersize=8)\n",
    "\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_xlabel('Round', fontsize=12)\n",
    "ax1.set_title('Accuracy Across Sequential Rounds', fontsize=14)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(['R0\\n(Direct)', 'R1', 'R2', 'R3'])\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 2: CIF Rate by Round (among R0 correct)\n",
    "ax2 = axes[1]\n",
    "x = np.arange(1, N_ROUNDS)\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    if model_key not in all_analyses or 'error' in all_analyses[model_key]:\n",
    "        continue\n",
    "    cif_rates = [\n",
    "        all_analyses[model_key]['cumulative_cif'].get(f'R{r}', 0)\n",
    "        for r in range(1, N_ROUNDS)\n",
    "    ]\n",
    "    ax2.plot(x, cif_rates, 'o-', label=model_labels[model_key],\n",
    "             color=colors[model_key], linewidth=2, markersize=8)\n",
    "\n",
    "ax2.set_ylabel('CIF Rate', fontsize=12)\n",
    "ax2.set_xlabel('Round', fontsize=12)\n",
    "ax2.set_title('CIF Rate by Round (R0 Correct Only)', fontsize=14)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(['R1', 'R2', 'R3'])\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Plot 3: Followed-Wrong Rate by Round\n",
    "ax3 = axes[2]\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    if model_key not in all_analyses or 'error' in all_analyses[model_key]:\n",
    "        continue\n",
    "    fw_rates = [\n",
    "        all_analyses[model_key]['by_round'].get(f'R{r}', {}).get('followed_wrong_rate', 0) or 0\n",
    "        for r in range(1, N_ROUNDS)\n",
    "    ]\n",
    "    ax3.plot(x, fw_rates, 'o-', label=model_labels[model_key],\n",
    "             color=colors[model_key], linewidth=2, markersize=8)\n",
    "\n",
    "ax3.set_ylabel('Followed-Wrong Rate', fontsize=12)\n",
    "ax3.set_xlabel('Round', fontsize=12)\n",
    "ax3.set_title('Rate of Following Trace\\'s Wrong Answer', fontsize=14)\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(['R1', 'R2', 'R3'])\n",
    "ax3.legend()\n",
    "ax3.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR_EXP}/exp_A1_E7_sequential.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✓ Figure saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 13: FINAL SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "summary = {\n",
    "    'experiment_id': 'A1_E7',\n",
    "    'experiment_name': 'Sequential Degradation',\n",
    "    'date': EXPERIMENT_DATE,\n",
    "    'hypothesis': 'Repeated exposure to contaminated traces causes cumulative degradation',\n",
    "    'design': {\n",
    "        'R0': 'Direct (baseline)',\n",
    "        'R1': 'First contaminated trace',\n",
    "        'R2': 'Second contaminated trace (different wrong answer)',\n",
    "        'R3': 'Third contaminated trace'\n",
    "    },\n",
    "    'n_problems': N_PROBLEMS,\n",
    "    'models': list(MODELS.keys()),\n",
    "    'results': all_analyses,\n",
    "    'key_findings': []\n",
    "}\n",
    "\n",
    "for model_key in ['sonnet4', 'gpt4o']:\n",
    "    if model_key not in all_analyses or 'error' in all_analyses[model_key]:\n",
    "        continue\n",
    "    analysis = all_analyses[model_key]\n",
    "    \n",
    "    r1_cif = analysis['cumulative_cif'].get('R1', 0)\n",
    "    r3_cif = analysis['cumulative_cif'].get('R3', 0)\n",
    "    \n",
    "    finding = {\n",
    "        'model': model_key,\n",
    "        'r0_accuracy': analysis['by_round'].get('R0', {}).get('accuracy', 0),\n",
    "        'r1_cif': r1_cif,\n",
    "        'r3_cif': r3_cif,\n",
    "        'cif_change': r3_cif - r1_cif,\n",
    "        'pattern': analysis['degradation_pattern'],\n",
    "        'cumulative_effect': r3_cif > r1_cif + 0.05\n",
    "    }\n",
    "    \n",
    "    summary['key_findings'].append(finding)\n",
    "\n",
    "save_json(summary, f'{SAVE_DIR_EXP}/results/exp_A1_E7_summary.json')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('EXPERIMENT A1-E7 COMPLETE')\n",
    "print('='*60)\n",
    "print(f'\\nResults saved to: {SAVE_DIR_EXP}')\n",
    "print('\\n' + '='*60)\n",
    "print('KEY FINDINGS')\n",
    "print('='*60)\n",
    "\n",
    "for finding in summary['key_findings']:\n",
    "    model_name = [n for n, c in MODELS.items() if c['short'] == finding['model']][0]\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  R0 Accuracy: {finding['r0_accuracy']:.1%}\")\n",
    "    print(f\"  R1 CIF: {finding['r1_cif']:.1%}\")\n",
    "    print(f\"  R3 CIF: {finding['r3_cif']:.1%}\")\n",
    "    print(f\"  CIF Change (R1→R3): {finding['cif_change']:+.1%}\")\n",
    "    print(f\"  Pattern: {finding['pattern']}\")\n",
    "    print(f\"  Cumulative effect: {'✓ YES' if finding['cumulative_effect'] else '✗ NO'}\")\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('INTERPRETATION')\n",
    "print('='*60)\n",
    "print('''\n",
    "If CIF rate increases from R1 → R3:\n",
    "  → Cumulative degradation effect exists\n",
    "  → Models become more susceptible with repeated exposure\n",
    "\n",
    "If CIF rate stays stable:\n",
    "  → Each exposure is independent\n",
    "  → No cumulative effect\n",
    "\n",
    "If CIF rate decreases:\n",
    "  → Possible adaptation/learning effect\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
